Agent-based simulations have become increasingly prominent in various disciplines. Like many others, I welcome this trend. But with the growth of the field and its growing interdisciplinary nature, the absence of standards in terms of model presentation and interpretation becomes ever more apparent (Lee et al. 2015; Macal 2016; Schulze et al. 2017). While too strict standards would certainly limit the creativity of the research community, some standardization is required to ensure that models can be reasonably compared and related to each other (see also Müller et al. 2014).

1.2Researchers have already responded to the need for standards in various practical ways. With regard to the presentation of agent-based models (ABM), in particular the description of their aim and functioning, Grimm et al. (2006) suggested the ODD protocol, updated in Grimm et al. (2010). The ODD protocol is meant to provide a common format for the description of ABMs and aims to facilitate their mutual relation and replicability[1]. Müller et al. (2013) extended the ODD protocol to facilitate the description of agent decision making. Similarly, the MoHuB framework tries to provide “a tool and common language to describe, compare and communicate” formal models of human interaction, particularly in the context of natural resource management (Schlüter et al. 2017). Another attempt in this direction is the TRACE framework, which was originally suggested in Schmolke et al. (2010) and updated by Grimm et al. (2014). It also seeks to increase the transparency and comparability of simulation models, yet it focuses on the way the functioning of the model is analysed and documented. Finally, the systematic design of experiments (DOE) offers an excellent framework for the study of model behaviour and the presentation of model results in a transparent and comparable manner (Lorscheid et al. 2011).

1.3In this paper I will make a different, yet complementary suggestion to increase the transparency and comparability of computational models: I will not focus on the presentation of ABM and their functioning, but on the ways models are related to reality and thus meant to create knowledge about the system under investigation (SUI). Models always differ from the system they are meant to represent and there are different epistemological ways of relating one’s model to reality[2]. Making differences between distinct epistemological strategies explicit would contribute to better comparability among computational models and thus, the cumulative growth of knowledge in the scientific community.

1.4The process of relating one’s model to reality is related to the intended purpose and model interpretation, and it entails two important activities: model verification and model validation. A great number of different and useful verification and validation techniques exist and the development of new tools is an active and successful area of research (Fagiolo et al. 2007; Rand & Rust 2011; Lorscheid et al. 2011; Lotzmann & Wimmer 2013; Alden et al. 2013; Lee et al. 2015; ten Broeke et al. 2016; Schulze et al. 2017).

1.5However, there are no standards with regard to verification and validation on two distinct and equally important levels. On the more practical level, there is no consensus on the ‘best’ tool for either verification and validation. This is because the complexity, the structure and the purpose of the model at least partly dictate the choice of verification and validation techniques (Sun & Müller 2013; Schulze et al. 2017). There is, however, a lively debate on the adequateness of different tools, and innovative new methods are constantly developed in the ABM community (Lee et al. 2015; Schulze et al. 2017; Schlüter et al. 2017).

1.6On the meta-theoretical level, there is no consensus on questions such as (1) “Is it necessary to verify and/or validate a model?”, (2) “To what extent is the verification and validation of a model even possible?”, or (3) “If model verification and validation are needed, what kind of verification and validation is adequate for the model at hand?” These are epistemological questions and they relate to the deeper problem of how a formal model, an agent-based model in particular, helps us to ‘understand’ a real system under investigation. While being more abstract, epistemological questions are by no means less important than the more practical questions raised above. Nevertheless, they usually receive less attention, which is why they are the main concern of the present paper.

1.7Discussing the coherence of models and their relation to reality is an important activity for every research community and it is essential that these discussions can be carried out effectively. This is exacerbated however, by the fact that different researchers often come with different views on how knowledge can and should be created about the system they investigate. Furthermore, the accepted criteria for what leads to an understanding of, or knowledge about the system under investigation can be very different between various scientific communities (Boero & Squazzoni 2005; Lehtinen & Kuorikoski 2007; Baumgärtner et al. 2008)[3]. Because of this, scholars also understand and value model verification and validation differently.

1.8In overcoming the resulting obstacles to successful cooperation, the analytical apparatus developed by philosophers of science can of great value. Their concepts and vocabulary can be helpful in aligning these different perceptions to each other and, thus, to facilitate the comparison and relation of ABMs and other formal models. Moreover, their analytical language can help to structure the debate about the adequate means for model verification and validation, and might facilitate the dialogue among modellers from different disciplines.

1.9Unfortunately, the literature on applied computational modelling and on the epistemology of modelling remain – so far – largely unconnected. Thus, one goal of this article is to introduce some epistemological concepts that can help applied modellers to carry out discussions about the application, justification and assessment of models more effectively. Alongside important analytical concepts of philosophers of sciences, a particular epistemological framework that may complement applied frameworks such as ODD+D or TRACE will be introduced.

1.10Thereby, the paper does not seek to resolve the philosophical controversy among the nature of models and their relation to reality. Rather, it tries to make accessible some of the philosophical concepts on models to the applied scientists using computational models.

1.11To achieve this we will take the following steps: The next section provides a short and concise review of concepts developed by philosophers of sciences that are helpful for the debate in the simulation community. These ideas will be summarized in a framework that helps clarifying the different strategies to give models epistemic meaningfulness. Then we will relate model verification and validation to this framework, describe the meta-theoretical relation between verification and validation, and discuss whether and when models should be verified and/or validated. In a subsequent step, we identify some immediate practical implications from the epistemological discussion above. Finally, we conclude the paper and summarize the implications for future research.

How Models Generate Knowledge about Reality
2.1This section introduces some of the key vocabulary and essential concepts developed by philosophers of science that are concerned with the question of how models create knowledge. Then it outlines a framework that accommodates these concepts in a way that is appealing to practising modellers. Initially however, the usefulness of referring to epistemology and the philosophy of science will be discussed.

The merits of an epistemological perspective on modelling
2.2Epistemology is “the study of knowledge and justified belief” (Steup 2016). In this field of philosophy one asks questions such as “What are the necessary and sufficient conditions of knowledge?”, “What are the sources of knowledge?” or “How can we generate knowledge about the real world?”. Here I will present a couple of reasons for why epistemological reasoning is important for applied scholars and comment on them one by one:

Epistemological arguments are important when choosing and justifying one’s modelling framework.
Epistemological reasoning is indispensable for relating results from different models to each other.
It helps identifying advantages and disadvantages of different modelling frameworks and suggests practical ways for combining them.
By dealing explicitly with an epistemological framework modellers can reflect upon and improve their own practices.
An epistemological framework can highlight trade-offs between various modelling desiderata and enables modellers to make more substantiated design choices.
An epistemological framework clarifies (1) the epistemic content of the sometimes vaguely used concepts of model validation and verification, (2) why and when validation and verification is is important, and (3) what we can expect from it.
2.3If asked why one is approaching a given research question with an agent-based model, the usual answers are of the kind “I want to study the role of the particular interaction structure, and in another modelling framework it is difficult to include this structure explicitly.” or “The heterogeneity of the actors can be represented very directly in an ABM, and this is important for my research question!”. These answers refer to particular epistemological statements because they formulate certain preconditions that must be satisfied by a model to be suitable to answer the research question of the modeller. Here, the implicit epistemological claim is that there are certain properties of the system under investigation that must be represented in the model for the model to be useful.

2.4Such implicit epistemological claims are often discipline-specific and, if not made explicit, a potential obstacle for interdisciplinary work. Economists, for instance, cherish properties that might receive less priority in other social sciences (Lehtinen & Kuorikoski 2007; Cartwright 2010; Reiss 2011). Rodrik et al. (2004, p. 133), for example, claim that “Historians and many social scientists prefer nuanced, layered explanations where these factors interact with human choices and many other not-so-simple twists and turns of fate. But economists like parsimony.” This suggests that economists pay less attention to the realistic-ness of particular modelling assumptions, but focus rather on clarity and simplicity of models[4]. To elucidate such epistemological differences (and to critically assess them from all viewpoints) is essential when we want to engage in interdisciplinary collaboration, and taking an epistemological perspective can help us to do so (Grüne-Yanoff 2013).

2.5More generally, engaging with an explicit epistemological framework can help researchers to reflect upon their actual modelling practices since it requires them to be very precise and explicit on how their model is expected to improve understanding of the target system. Additionally, epistemological frameworks can highlight trade-off among different modelling desiderata, such as transparency, generality, or precision. Thereby, they can help us in making more explicit and grounded design choices, and, in the end, to improve upon our established modelling practices. The identification of trade-offs might also suggest ways in which we can complement our model with other (model-based or non-model-based) perspectives on the target system, which might help remedying the inevitable shortcomings of our model.

2.6Epistemological reasoning can also help us relating results obtained from different methods to each other. For example, there is currently a debate among policy makers and economists on the potential welfare and job effects of a free trade and investment agreement between the European Union and the United States. Francois et al. (2013) - and many others - have tackled this question with a Computable General Equilibrium (CGE) model, the current standard in economic research practice. The authors conclude that the agreement would lead to generally favourable results. Capaldo (2014) uses a conventional macroeconomic model to study the same question but expects job and welfare losses for Europe. Which model is ’better‘, or, which conclusion should form the basis for the decision making of policy makers? Some might argue that the assumptions of Capaldo (2014) are more adequate than those of Francois et al. (2013). Others might trust more in the CGE model because it relies on economic equilibrium, it is easier and thus more transparent and parsimonious. To trace different sources for distinctive policy implications, and to prioritize models in terms of the insights they create, we again need to refer to the epistemological questions posed before. Using explicit frameworks and precise language facilitates this task.

2.7The previous argument relates to a more general finding: different modelling frameworks have respective advantages and disadvantages that are not explicitly reflected upon in disciplinary practice. Taking an epistemological perspective can help to highlight them (Grüne-Yanoff 2013). For example, agent-based economic models are - generally speaking - quite flexible in their assumptions. General equilibrium models[5] are - again, generally speaking - more parsimonious and often allow for analytical solutions. Choosing the right modelling framework and the right model requires a reflection of their strengths and weaknesses. Sometimes, there is no ‘right’ model at all and it makes sense to use multiple models and look at the system under investigation from different angles (Aydinonat 2017). In any case, carrying out a balanced choice of methods and a successful model triangulation is particularly important in the context of interdisciplinary work and again, requires epistemological reasoning (Grüne-Yanoff 2013).

2.8Researchers in the simulation community are often concerned with the problem of choosing the right set of methods for model verification and validation. But the question of when and why verification and validation is important, and how this relates to the purpose of modelling, receives less attention. To argue why a particular method for model validation is important means to make a statement on how the link between the model and reality should be assessed. This, as any other argument made in this context, is an epistemological argument.

2.9In all, there are a number of arguments for why epistemology is important. In contrast to the discussion of the adequate means for model verification and validation, the most important point about epistemological arguments is that they are made explicit. Using an explicit framework helps us to compare models because the way they are meant to explain becomes more explicit, transparent, and, thus, comparable.

Models and reality: A short review of key concepts
2.10The aim of this section is to introduce applied modellers to some of the key concepts developed by philosophers of science. The merit of these concepts is that they allow us to be more precise about how our models can be used to create knowledge about reality. Of course, the philosophical literature on the epistemology of models is extensive and it is beyond the scope of this article to provide an exhaustive review. Rather, I will attempt to provide a concise overview over some of the key concepts introduced by philosophers of science that are particularly useful for the topic of this paper and that can help applied modellers. For a more extensive review from a philosophy of science perspective see e.g., Grüne-Yanoff (2013).

2.11Before we begin, the scope of this review needs to be clarified. First, there is an extensive body of literature concerned with the ontological nature of models, i.e., the question: “What are models?”. There are many suggestions in the literature, ranging from the idea of models as mathematical objects to the idea of models as fiction. For the present discussion the question on the ontology of models is of secondary importance since all the arguments below are compatible with most prominent conceptions. For a review of the relevant literature see e.g., Gelfert (2017).

2.12Second, there is a literature on the function of models (see e.g., Morgan & Morrison 1999; Peschard 2011 or Gelfert 2016 for initial overviews). In the following, I will focus on contributions that treat models as representations of a target system that are geared towards a better understanding of this target. There are other purposes for models, such as entertainment, measurement or further model-construction, but here I focus on models that are used to represent and understand certain target systems in the real world.

2.13Third, whenever we wish to represent and explain a target system there are alternatives to models. As argued in Weisberg (2007), the distinctive feature of modelling is that the system under investigation is studied indirectly: we build a model, we analyse the model, and then we relate the model to reality. An alternative procedure, abstract direct representation, lacks the intermediate step of building a model as a surrogate of the system under investigation: here one describes and studies the target system directly. Yet, for the purpose of this paper, we will be confined to models as means to represent and study reality.

Key vocabulary
2.14I will now start introducing some basic vocabulary used by philosophers of science. This not only helps applied researchers to specify their meta-theoretical considerations more precisely, it also helps them in accessing the epistemological literature more easily. For a summary of all concepts see Table 1.

2.15First, models that serve as representations necessarily have a target, i.e., the system that the model is meant to represent. The target system does not need to be one particular, or even a real system. Schelling’s segregation model, for example, is usually not meant to represent one particular city, but an abstract city such that the argument applies in many instances. We call such targets generalized targets (see e.g. Weisberg 2013, p. 114). Other models are meant to represent targets that do not, or even cannot, exist (so called hypothetical targets, see e.g., Weisberg 2013, p. 121). For example, there are models in computational biology that represent populations of three-sex species, something that has never been found in reality. Yet by showing that a three-sex population comes with enormous costs, such models provide a potential explanation for why there are no three-sex populations in reality (Fisher 1930; Weisberg 2007).

2.16 Second, although we do not want to concern ourselves too much with the ontology of models, it makes sense to distinguish three different kinds of structure that can serve as models (Weisberg 2013), sometimes referred as the O-objects, which provide for the ‘material’ of which the model is built. The first kind are physical models such as the San Francisco Bay model (Army Corps of Engineers 1981) or the Monetary National Income Analogue Computer MONIAC, a hydraulic model of the economy (Bissell 2007). Such models are not very common in the social sciences and will not be the subject of our following considerations. Second, mathematical models are mathematical structures such as functions and state spaces. They are very common in the social sciences. Third, computational models are sets of procedures.

2.17One might well argue that computational models are in fact a subset of mathematical models because the procedures can be described mathematically (Epstein 2006). A similar point is made by philosophers who argue that computational models do not pose any specific philosophical problems and can be treated with the same tools as mathematical models (Frigg & Reiss 2008). The main argument of treating them as a separate category is pragmatic and refers to their different use: the way in which results are derived differs (Lehtinen & Kuorikoski 2007, p. 310) and – because they usually do not allow for analytical proofs – involves a certain “epistemic opaqueness” with regard to the precise derivation of the results (Humphreys 2009). Also, computational models are often generative (Epstein 2006): in contrast to most mathematical models, they generatively ‘grow’ their results from the initial conditions, thereby automatically suggesting concrete mechanisms on how the model results could come about in the target.

2.18This distinction of modelling categories relates to the concept of representational capacities of structures: not all structures can be used to represent any system because some structures are too rigid and not expressive enough. Here, philosophers distinguish between (1) dynamical sufficiency and (2) mechanistic adequacy. These concepts are useful if one wishes to justify the choice of the modelling framework one is using. ‘Dynamical sufficiency’ refers to a model’s capacity to reproduce patterns observed in the target, ‘mechanistic adequacy’ refers to its capacity to represent the mechanistic structure of the target. If we consider the claim that agent-based models are preferable to DSGE models because (1) it is easier to consider the direct interaction of heterogeneous economic agents in these models, and, (2) they produce better predictions, then (1) means that ABM are superior to DSGE models in terms of their mechanistic adequacy, and (2) refers to their alleged superior dynamical sufficiency.

2.19Many philosophers of science make the distinction between models and model descriptions (see e.g., Weisberg 2013, ch. 3)[6]. As indicated above, we consider models to be mathematical structures or sets of procedures. It is important to distinguish between these models and their descriptions (Giere 1990; Weisberg 2013). The descriptions can consist of equations, computer code, pseudo-code, graphs, pictures and most importantly, words. The relation between models and model descriptions is many-to-many: the same model can be described in very different ways. Schelling’s segregation model, for instance, can be described via source code, equations, or words, among others. Yet at the same time, descriptions usually do not describe a model in every detail and some aspects are frequently omitted. Thus, the same description often specifies different models, and the less precise the description, the more models it can specify. In the following we focus on models, rather than on their descriptions.

2.20Many modern accounts argue that models are not representations by their very nature, but that they are made representations by the explicit stipulation of the modeller (Peschard 2011, p. 337). In effect, this implies that “models do not have a single, automatically determinable relationship to the world” (Weisberg 2007, p. 218), but that model users have to specify how they intend to use a model. These intentions underlying any model are summarized as the construal of researchers and include the assignment (or ‘denotation’) and the intended scope of the model.

 
Table 1: A table summarizing the concepts introduced in this section
Term/Concept	Description
Target of a model	The real or fictional system/object that a model intends to represent. There are particular, general or hypothetical targets.
O-object	The fundamental structure (or ‘material’) of the model, determines the type of the model.
Type of model	Weisberg (2013) suggests there are three types, depending on the kind of O1-object used to construct the model: physical models (consisting of matter), mathematical models (consisting of mathematical objects) and computational models (consisting of procedures).
Representational capacity	The degree of ‘expressiveness’ of the structure of a model, i.e., its ability to represent a target in line with the fidelity criteria provided by the user.
Fidelity criteria	The standards used by the model user to evaluate the ability of a model to represent its target. Can be divided into at least dynamic and representational fidelity criteria.
Dynamic fidelity criteria	The desired degree of similarity between the model output and the target, often specified as acceptable error bands.
Dynamic sufficiency	The degree of structural sophistication a model must have to produce an output reasonably similar to that of its target, i.e., as similar as articulated in the dynamic fidelity criteria.
Representational fidelity criteria	The standards used by the modeller to evaluate the ability of a model to represent the causal structure/mechanisms of the target.
Mechanistic adequacy	The degree of structural sophistication a model must have to mimic the causal of its target adequately, i.e., as close as articulated in the representational fidelity criteria.
Model description	The description of the model is different to the model itself. The relationship between models and descriptions is many-to-many.
Scope	Clarification of what features of the target the model intends to represent.
Assignment	Clarification of which part in the model corresponds to (or ‘denotes’) which part in the target, and which parts of the model are to be ignored.
Denotation	A binary relation between a model and a target; established via the stipulation of the model user to use the model as a representation of the target.
Full explanation	Description of why a certain fact occurred at a particular time in a particular way. Requires the description of all the causal factors that have produced the fact.
Partial explanation	Description of the role of some explanatory factors underlying the occurrence of a fact. Involves idealization since not all causal factors were considered.
Potential explanation	Description of the factors that could have produced a certain fact. Not confined to actual targets; occurs frequently when general, hypothetical, or theoretical targets are concerned.
Exemplified properties	The relevant properties a models exemplifies under a given interpretation.
Model key	A dictionary explaining to what properties in the denoted target the exemplified model properties shall correspond.
Imputed properties	The properties that the model (truly or falsely) imputes on its denoted target.
Mental model	The perception of the researcher of her subject of investigation; also contains her Weltanschaung or ‘pre-analytic Visions’.
2.21The assignment – or the ‘denotation’ – of a model specifies which part of the model should be mapped on which part of the target (Weisberg 2013, pp. 39-40). Let us consider a macroeconomic model consisting of a few representative agents as an example. One of the agents is called ‘representative household’ and it should represent households in the real world. Another agent is called ‘representative firm’ and it should represent firms. Thus, in total the assignment of the model specifies which target system is actually meant to be represented by the model as a whole.

2.22The intended scope also refers to the coordination of the model and its target: it specifies which particular parts of the target should be represented by the model (Weisberg 2013, p. 40). For example, the intended scope of the original Lotka-Volterra model was the relationship between the abundance of predators and prey. Many aspects of the relationship between predators and prey that are outside the intended scope of the model, such as the spatial distribution of predator and prey populations. Correspondingly, spatial relationships are not modelled explicitly, so the model would imply that the spatial distribution of the populations has no effect – a more than questionable statement. By making the intended scope of the model explicit, i.e., to clarify explicitly that the model is not meant to consider the role of spatial relationships, one makes sure that models are not used for – or judged on the basis of – questions and applications they were not designed for (and for which they might not be well suited).

2.23As emphasized above, different disciplines usually understand ‘explanation’ differently (Lehtinen & Kuorikoski 2007). Yet there are some broad categories of explanation that might be useful to distinguish (Grüne-Yanoff 2010, pp. 37-43):

Full explanation: A full explanation, also known as ‘how-actual explanation’ shows how a concrete phenomenon has occurred. This entails to describe in detail the causal history preceding the concrete phenomenon and to identify all the relevant causal mechanisms involved. Outside the natural sciences such explanations are very rare.
Partial explanation: In the case of partial explanations the model isolates some factors deemed important and idealizes away from others. Thus, one explicitly does not include all relevant factors in the model (which is impossible for more complex systems anyway). Although partial explanations are much easier to reach than full explanations, in most applied and social sciences it is still almost impossible to show that a certain model provides for a partial explanation since one can never be sure to have included all the relevant factors.
Potential explanation: The most common type of explanation in the context of computational models are potential explanations, also known as how-possible explanations. A potential explanation provides a model that represents mechanisms that could in principle have brought about the phenomenon of interest. The Schelling model, for example, provides a how-possible explanation for segregation in a city (Ylikoski & Aydinonat 2014). We do not know whether the underlying mechanisms have actually brought about segregation, but the model shows that they could possibly have brought about segregation[7]. In contrast to full or partial explanations, how-possible explanations are not necessarily directed towards concrete events that have happened in reality, but might also refer to generalized targets (such as ‘segregation’) or theoretical models themselves (e.g., cellular automata), or they might simply illustrate the functioning of purely theoretical mechanisms (Weisberg 2013; Ylikoski & Aydinonat 2014).
2.24Finally, there are several answers to the question “What makes a model an epistemic representation of a target?”, i.e., what are the features of models in virtue of which they represent their target? Here, I will focus on a particular account of models that answers this question, and is appealing for several other philosophical arguments: the so called DEKI account as developed in Nguyen (2016) and as introduced by Frigg & Nguyen (2016)[8].

When is a model a representation of a target? The DEKI account of modelling
2.25The DEKI account as introduced by Frigg & Nguyen (2016) starts with the notion of a model M and a target T and then formulates demands this model must satisfy to count as a representation of T (the following elaborations will be summarized in Figure 1). A model within the DEKI framework is a certain structure or object, commonly referred to as an O-object. As argued above, we will not delve deeper into the ontological status of models. For us, the O-object corresponds to the type of model and is thus a set of mathematical objects (for the case of mathematical model) or a set of procedures (for the case of computational models). To count as a model however, the O-object must come with a certain interpretation that is to be supplied by the model user. We have already specified two important aspects of the interpretation above: the assignment and the intended scope.

2.26Such an interpretation makes the initial O-object to count as a Z-representation. A Z-representation is a one-place predicate and Z is a place-holder for the kind of the target of the model. For example, a picture p of a woman is a woman-representation: WOMREP(p). This does not necessarily mean that it represents one particular woman, it could well be a fictional woman. This is important since some models represent general (such as cities in general instead of a particular city) or hypothetical (such as a three-sex population) targets. As an example, consider a computational agent-based model that is meant to represent a national economy. If this interpretation is explicit we could state MACROECON(c), where c stands for a set of algorithms and MACROECON(c) reads as: the set of algorithms c is interpreted as a macroeconomy-representation. Why do I not say ‘representation of a macroeconomy?’ Because this could wrongly be interpreted in the sense that c is meant to represent one particular macroeconomy. We want to be less restrictive in our claims and only say that c is interpreted (and thus stipulated) as a macroeconomy-representation.

2.27Now that we have clarified the notion of a model M as an O-object accompanied by an interpretation that turns it into a Z-representation, we can specify the four demands that the model must meet to count as a representation of its target T:

The model M must denote its target T.
The model M must be a Z-representation exemplifying properties P1,...,Pn.
The model M must come with a key K that indicates how the properties P1,...,Pn can be translated into a set of features Q1,...,Qm.
The model M must impute some features on its target T .
2.28The first demand is straightforward: a model user must make clear that he uses the model to represent a target, and she must specify the target the model is meant to represent. The crucial point here is that the model user must make clear that he uses the model as a representation of a target. This is important since a set of algorithms constituting the Schelling segregation model does not by its nature represent segregated cities. Only if the model user makes it explicit that she uses this set of algorithms to represent a city, the set of algorithms becomes a model of a city.

2.29The second demand requires that the Z-representation must exemplify certain properties P1,...,Pn. Exemplification refers to the instantiation of a certain property, P, by directly referring to this property. Instantiation must not be interpreted literally, which is why the accompanying interpretation of a model is so important: no agent in an agent-based macroeconomic model literally has some wealth. Rather, we interpret the model such that the agents in the model instantiate properties such as wealthiness. For a smooth and transparent use of a model, it is important that these interpretations are carried out as explicitly and clearly as possible.

2.30The third step is to link the properties of the model, P, to the relevant properties of the target system, Q. How to translate the properties exemplified by the model, P, to the properties of the target, Q, must be specified by a key (or a ‘dictionary’). The simplest example for a key is the legend of a map: it explains how certain points on the map should be interpreted in the area represented by the map. For instance, a big red dot represents a capital, and 1 cm of a black line represents 1000 km of a small road.

2.31Finally, at least one property Q must be imputed to the target system. Which properties are imputed depends on the intended scope of the model. Such imputations can be false: a model can make a prediction about how the target behaves, but it behaves differently. A model that makes false predictions about its target does not stop representing this target, and imputing properties on the target - it just misrepresents the target because it imputes the properties wrongly on the target.

2.32Let us summarize what has been said about the DEKI account so far in Figure 1: we start with an O-object, which can be a set of algorithms. We supply an interpretation according to which the O-object is a Z-representation, for example an economy-representation. We make clear that the model denotes the target economy. Also, the model I-exemplifies certain properties P1,...Pn, e.g. a certain wealth distribution of the software agents (this means it exemplifies them under the interpretation I). We supply a key that maps the properties of the models to the properties of the target economy Q1,...,Qm. We then impute the resulting properties Q1,...,Qm on the target economy. This can lead to true or false statements, depending on whether the imputed properties correspond in their values to the properties of the target.

2.33A big merit of the DEKI account of Frigg & Nguyen (2016) is that it helps us understand how both very idealized and general models, such as the Schelling model, and very complex and applied models, such as the disease model of Eubank et al. (2004), serve as representations.

Adding details: Dynamics, mental and conceptual models
2.34We now want to add some more specificity to the framework sketched in Figure 1. There are at least three aspects of the model building process that are still missing from Figure 1: the time dimension of models and their targets, the mental models of the researchers, and the conceptual model, which is to be distinguished from the final computational model.


Figure 1. A visualization of the basic components of the DEKI framework. It explicates how the computational model M1 represents its target T.
2.35First, many computational models are dynamic models and they are related to their target over time. The current visualization of the DEKI framework does not consider this. To avoid misunderstandings I will adjust the figure so that the model exemplifies potentially different properties at different points of time.

2.36Second, the current visualization does not consider the mental models of the researchers. With mental models I refer to the representation of reality we construct in our brains. Since reality is too complex to be perceived in its entirety, we need to reduce its complexity by abstracting from details, thus building a coarse-grained representation of reality that our mind can process. Cognitive scientists refer to these representations as ‘mental models’ (Johnson-Laird 2005). The basic idea has been nicely summarized already by Forrester (1971):

"Every person in his private life and in his business life instinctively uses models for decision making. The mental image of the world around you which you carry in your head is a model. One does not have a city or a government or a country in his head. He has only selected concepts, and relationships between them, and uses those to represent the real system” (Forrester 1971, p. 112).
2.37Although mental models are distinct from the models we build within the scientific discourse, they do play a role in the construction of scientific models. Considering them in our framework helps us to explicitly accommodate the Weltanschauungen of the researchers which, at least to some extent, always impact our scientific practice (see already Weber 1922): “no model could claim absolute objectivity as each is also subject to the modeller’s subjectivity, view and understanding of the world, and proneness to mistakes” (Augusiak et al. 2014, p. 119). Considering mental models explicitly in our framework highlights this important aspect[9]. Note that the relationship between mental and computational models is not a relationship of representation. A mental model does not represent a computational model or vice versa. Rather, a mental model always implicitly pre-dates a computational model since it allows us to perceive and cognitively process information about the target.

2.38The final – and most important – addition to Figure 1 that is necessary in the context of computational models is that of a conceptual model[10]. The conceptual model is the intermediate model that is created before one implements a computational version of it (Augusiak et al. 2014). It summarizes the aspects of the target considered to be relevant and important for the final computational model. Thereby, it also is a representation of the target, although a much cruder one than the computational model. In practice, the people building the conceptual model are not necessarily the same that build the computational model: a research group might consist of theorists and programmers, with the former designing the conceptual model, which is then implemented by the programmers. For our purposes, it is useful to put the conceptual model into our visualization since it will later help us to accommodate model verification and validation in this figure. Again, there is no relationship of representation between the conceptual and the computational model. Rather, both of them represent the target, and the computational model is a computational implementation of the conceptual model. Alternatively, we can think of the conceptual model as a coarse-grained description of the computational model.


Figure 2. A complete visualization of the DEKI framework for computational models. Note that there is no representational relationship between the computational and the conceptual and/or mental model. Rather, mental and conceptual models predate computational models. The latter are an explication and implementation of the former. This figure omits the representational relationship between the conceptual model and the target system: the former should certainly represent the latter since it provides the basis for the computational model. Mental models represent the target as well, but often implicitly, since they are seldomly expressed explicitly.
Taking stock
2.39Integrating all the previous considerations into Figure 1 results in the more complex but complete Figure 2. The concepts introduced so far are summarized in Table 1.

2.40For most practical applications, Figure 2 is over-loaded and contains too much details. This is why we will reduce it for the further discussion of verification and validation (see Figure 3a). Also, for applied researchers describing their model using all the concepts introduced in Table 1 would probably be too much of an issue. Therefore, one might use a form as the one in Figure 3b, which could be provided with the model description as an appendix, similar to the ODD protocol.


Figure 3. The DEKI framework in a more concise visual presentation, and a form that helps researchers to be transparent with regard to how a model is intended to be used.
Aligning Model Verification and Validation within the Epistemological Framework
3.1The epistemological framework introduced above allows us to be precise about the role of verification and validation in the modelling process. While some authors have suggested dismissing the terms because of their ambiguous and careless use in the literature (see e.g., Augusiak et al. 2014; Schulze et al. 2017), I believe that precisely defined, they can highlight two important aspects of model evaluation, which are both important, but conceptually distinct. For the sake of transparency, I relate my terminology to that of Augusiak et al. (2014) in the appendix of this paper. There, the value-added of the terms ‘verification’ and ‘validation’, which will now be clarified, is explained in more detail[11].

3.2With verification I refer to the act of testing whether the model does what it is supposed to be doing, i.e. whether it adequately implements the conceptual model and whether it is free of bugs or other implications not intended by the modeller. The verification of a model takes place after the model has been built (and possibly during the model building process) and should precede any application and/or validation of the model.

3.3Verification usually involves two steps: (1) study what the model is doing, and (2) compare this to what the model is supposed be doing. The first step is often referred to as model exploration. The second step can be carried out in a twofold sense: first, one scrutinizes whether the model does what the programmer wants the model to do. Such scrutiny is mostly concerned with identifying bugs and programming errors. Second, one investigates whether the model adequately implements the underlying conceptual model. This is usually more demanding. In case the people programming the model differ from the people setting up the conceptual model, this step necessarily involves a group effort where the programmers explain the functioning of the model and the theorists (or other stakeholders involved in the model design) assess the adequacy of the implementation. It is worth noting again that both activities are only concerned with the computational and the conceptual model. The target system has not yet a role to play.

3.4Consequently, sensitivity analysis would also be considered some form of model verification since it exclusively aims at understanding the behaviour of the model. For more details see e.g. Beck (2002), or Rand & Rust (2011) for a nice summary and ten Broeke et al. (2016) for a review of different tools for sensitivity analysis[12].

3.5The best method for model exploration is mathematical proof that certain inputs produce a particular output. For computational models, proofs are usually not a viable option and numerical experiments using a computer are required. The resulting “epistemic opaqueness” (Humphreys 2009) is one reason why we have followed Weisberg (2013) in distinguishing between mathematical and computational models, although the distinction collapses on an abstract level (Epstein 2006).

3.6Model validation means to test whether the model is actually a reasonable representation of the target (Rand & Rust 2011, p. 187). Because ‘reasonable’ can have different meanings, there are different forms of model validation to be discussed below. The correct choice depends on the purpose of the model, the desired mechanistic adequacy and dynamic sufficiency, and the imputed properties of the model. However, all forms of validation are distinguished from verification by the fact that they are concerned with the relationship between the model and the target of the model.

3.7We will now align model verification and validation within the framework developed above. As indicated in Figure 4a, model verification is concerned with the internal consistency of the computational model and its fit to the underlying conceptual model. Examples of methods that are used to verify models are unit testing (i.e. explicit tests for important aspects of the code, e.g. via assertions), code walkthroughs (i.e. an explicit description of what every line of code does), degeneracy testing (i.e., testing whether the code produces the desired output for extreme values of input), or the implementation tools ensuring the traceability of model outcomes (i.e. a clarification of how each step in the model relates to previous steps and design decisions; see e.g., Scherer et al. 2015 for a description and an illustration for the case of large-scale policy models).

3.8Considering these methods and keeping in mind that often “confirming that the model was correctly programmed was substantially more work than programming the model in the first place” (Axelrod 1997) we might want to keep the effort needed for verification at a minimum and thus ask the question: “What can we do to make model verification easy?” Firstly, we should build simple models. The simpler the model, the easier verification (ten Broeke et al. 2016). This is obvious since the simpler the model, the fewer variables and mechanisms one has to check. In the best case, the model is in a form that makes it even amendable for analytical proofs.

3.9Secondly, we should build transparent models. There are a number of tools developed in the simulation community to increase model transparency: the systematic DOE (Lorscheid et al. 2011) provides guidance for the analysis of model behaviour and exploration of the role of key parameters. Troitzsch (2017) describes a way to reconstruct simulation models along the line of the ‘non-statement view of models’ and explains how such a reformulation can increase the transparency of the simulations, and the functioning of the models. For more complex models, particularly those geared towards policy evaluation, Scherer et al. (2015) outline a framework focusing on the implementation of traces, which are designed in a way such that the output of the model can be linked to the initial input of stakeholders, the background knowledge and specific model design decisions. This framework is more complex and currently implemented for one particular class of models, yet it has the potential to help not only modellers, but all stakeholders of a model to better understand what the model does, why it does it, and how this can be justified given the background information available. For similar expositions that seek to make verification more open and inclusive, see also Wimmer et al. (2012) or Lotzmann & Wimmer (2013).


Figure 4. The place of model verification and the different forms of validation within our epistemological framework.
3.10Of course, several of the frameworks surveyed in the introduction can also help to make models more transparent. In all, the more transparent the model, the easier verification: a model that is written in simplified equations, well-documented computer code or a clear language is - ceteris paribus - easier to be verified than other models.

3.11We now move to model validation. There are several forms of validation and they partly echo the different perceptions researchers have in mind when they talk about ‘understanding reality’ (see above). At least the following four forms of model validation can be distinguished (Tesfatsion 2017):

Input validation
Process validation
Descriptive output validation
Predictive output validation
3.12In contrast to verification, these four activities assess the relation of the model to reality[13]. I will discuss the four forms one by one and relate them to each other in the next sub-section. In the appendix I relate this terminology to that of Augusiak et al. (2014).

3.13Input validation - as illustrated in Figure 4b - assesses the ability of the model at t=0 to represent certain aspects of the system under investigation, i.e., to impute many properties correctly on the target. In an ABM of a financial market, for example, input validation concerns the question of whether the number of traders is similar in the real market and the ABM, whether their initial wealth distribution is the same, or whether their decision-making procedures match. Some inputs to a model are easier to validate than others: while the initial wealth distribution of the trader just mentioned might be inferred from empirical data, their decision making algorithms might never been identified precisely, yet there are without doubt more and less accurate descriptions of their decision making.

3.14Generally, it is always easier to validate aspects of a model that are a direct representation of real-world objects (Schulze et al. 2017). For example, human beings are boundedly rational, use heuristics and do not directly maximize something such as utility (Gigerenzer 2015). So, representing human beings not as locally constructive and boundedly rational agents, but as utility-maximizers might be a valid and useful modelling approach, but it makes it much more difficult to validate the model in terms of input-validation (Schlüter et al. 2017). Furthermore, input validation is facilitated if aspects of reality are represented explicitly: If in our model of the financial market, traders explicitly trade directly with each other, the interaction network specifying their inter-action structure can be validated against real-world data. This requires the model to be sufficiently complex. If we use indirect representations to keep the model simple, e.g. an Walrasian auctioneer[14], input validation becomes more difficult (Balbi & Giupponi 2009).

3.15In all, input validation is facilitated by sufficiently complex models, which avoid as-if representations and good data.

3.16Process validation assesses the credibility of the mechanisms in the model, i.e., the mechanistic adequacy of a model (see Figure 4c). Process validation is exacerbated by the fact that in reality, “most mechanisms are concealed, so that they have got to be conjectured” (Bunge 2004, p. 186). Because mechanisms are not directly observable, no model will ever be fully process-validated. But there are many reasonable ways to assess the question of whether the implemented mechanism A is more or less likely to operate in the real world than mechanism B. These ways include expert and stakeholder validation (also known as ‘participatory validation’ Voinov & Bousquet 2010; Smajgl & Bohensky 2013), process tracing (Steel 2008, ch. 9), face validation (Klügl 2008) and a clever use of experiments (e.g. Bravo et al. 2015)[15].

3.17It is indeed one of the main epistemological merits of ABM that they are generative, i.e., necessarily suggest mechanisms that can - in principle - be tested concerning their plausibility with regard to the target system (Epstein 2007). This is facilitated by the rise of object-oriented programming, since the distinction between instances and methods in the model facilitates the interpretative relation to real world objects and mechanisms.

3.18What kind of models are easier accessible for process validation? First, the more direct the representation of the real objects and the mechanisms, the easier the assessment of the mechanism (Macal 2016). Object-oriented models tend to be easier to process-validate because instances in the model often correspond to objects in reality, and methods correspond (at least partly) to mechanisms. Second, a modular design also makes it – ceteris paribus – easier to process-validate a model.

3.19Next, we turn our attention to descriptive output validation. Here one asks to what extent the output of the model can replicate existing data, i.e., to understand the dynamic sufficiency of the model (see Figure 4d). Or, referring to Figure 3a, we test whether the imputed states in t1 are correct. For example, if we have built a model for the UK economy, we may compare the time series for GDP from the model with real-world data on the GDP of the UK.

3.20Although descriptive output validation is maybe the most commonly used form of validation (at least in economics), there are some problems with this kind of validation that one has to keep in mind:

Empirical risk minimization: in most cases, one is interested in minimizing the prediction risk of models. Because the prediction risk of a model is unobservable, one often uses the empirical risk as an approximation or estimator for prediction risk. This is a mistake because the empirical risk is minimized by choosing a model with many free parameters, while prediction risk increases with too many free parameters.
Overfitting: this is a direct corollary from the first point. If a model has so many free parameters that it can be calibrated to existing data very well, it is likely to perform poorly for new data.
Equifinality: usually, we can think of many mechanisms that can bring about the same result. The mechanism-to-function mapping is many-to-one (Gräbner & Kapeller 2015, p. 435). Therefore, if we are interested in mechanism-based explanation, the calibration of a model to existing time series alone is insufficient because it tells us relatively little about what mechanisms were actually at work.
3.21A good illustration of the limits of descriptive output validation is given by Janssen (2009) who discusses the famous Anasazi model (Axtell et al. 2002) and shows how many important questions still remain open, despite the model having a very nice fit with historical data (see also Grüne-Yanoff 2013). Without additional validation forms being applied (in this case particularly further process validation), the model can ‘explain’ the dynamics of the Anasazi only in a limited way.

3.22What makes a model easy to validate in terms of descriptive output validation? Ceteris paribus, the more complex the model and the more free parameter it has, the more successful it will be in terms of descriptive output validation. Grimm (2005) describes the practice of ‘pattern oriented modelling’ as a less naive form of descriptive output validation. Here, one tests how several model specifications can replicate an observed pattern, eliminates the unsuccessful one and proceeds with more detailed patterns until all but a very few candidate models remain.

3.23Finally, predictive output validation basically asks how well the model can be trained to predict future states of the system. Its idea is also illustrated in Figure 4d, but in contrast to descriptive output validation, the real world data is separated into a training set and a test set. This way, one avoids the problem of over-fitting and empirical risk minimization. This form of model validation is extremely illuminating, but not always applicable because of data requirements.

3.24Furthermore, any form of output validation should be complemented with process validation since being able predict without knowing why one is able to predict is often problematic. To see this, consider the following example[16]: Babylonian astronomers were able to predict solar eclipses and planetary movements with astonishing accuracy more than three thousand years ago. They based these predictions on extensive and careful observations and the application of geometry, without having any deeper understanding of the causes for these movements and the physical relationships between planets, moons, and the sun. Their way of predicting solar eclipses is nevertheless successful since the periodicity of the movement of celestial bodies does not change. The periods between two solar eclipses are the same today, as they have been 3000 years ago.

3.25The preceding example shows that making statements about the ‘validity’ of a model requires meticulous formulation. Fortunately, the kind of validation techniques just reviewed correspond closely to the different types of model validity as discussed in the philosophical literature (e.g. Grüne-Yanoff & Weirich 2010, pp. 37-41). Structural validity demands that a model both predicts the behaviour of its target and adequately represents its mechanistic structure, i.e., not only are future states predicted correctly, it is also explained how and why these states come about. To show that a model is structurally valid one has to employ all four validation techniques presented. Predictive validity requires a model to predict future behaviour of its target. This requires predictive output validation. And replicative validity requires a model to replicate the observed behaviour of the target. Consequently, it requires us to employ descriptive output validation.

3.26Stating that a model has been validated successfully must also take into account the fidelity criteria as discussed in the previous section (see also Table 1). If a model is intended only as a very rough illustration of some isolated mechanisms, stating that it is not output validated is not a sensible statement. Yet if the same model is claimed to have predictive power, output validation becomes essential. For model developers and users, this means that they should be very explicit with regard to the fidelity criteria they employed.

Trade offs in practical modelling design
3.27What is the relation between verification and the various types of validation? Is there a model design that scores optimal in all four activities? Unfortunately, for the single model this is usually not the case. There are trade-offs in terms of modelling design that make it practically impossible to design the ‘perfect model’.

3.28Before turning to practical issues, we will have a short view on the philosophical literature on trade-offs in modelling. This literature dates back to Levins (1966) who discusses several modelling desiderata in the context of population modelling. He argued that there are trade-offs with regard to generality, realism, and precision of a model. More recently, Matthewson & Weisberg (2008) reconsidered Levin’s arguments and provide a clearer taxonomy of trade-offs in the context of model design.

3.29First, they distinguish between ‘simple’ and ‘complex’ trade-offs[17]. The first correspond to pragmatic constraints: increasing the quality of the model with respect to one desideratum makes it more difficult to realize another desideratum. We will be concerned with the simple trade-offs below when we discuss whether increasing the validity of a model in one dimension makes it more difficult to keep or increase the validity in another dimension.

3.30‘Complex trade-offs’ relate to more fundamental relationships between model desiderata that cannot be overcome by the investment of more time, thought or computational power. In the more formal part of the paper Matthewson & Weisberg (2008) prove the existence of fundamental trade-offs between the precision of a model description and the generality of the models picked up by the description. They also argue that the less homogeneous and more complex the target, the more profound the trade-offs, and the smaller the intended scope of a model, the less severe the trade-offs.


Figure 5. The relationship between verification and the different kinds of validation.
3.31The scope and relevance of these results are still debated in philosophical literature, as are their practical implications. The interested reader might refer to the more in-depth contributions of, for example, Odenbaugh (2003), Matthewson & Weisberg (2008) or Goldsby (2013). In the following we will treat a successful model validation and verification as model desiderata and ask whether there are (simple or complex) trade-offs among them. Thus, we will ask for example, whether models that tend to be easier to verify tend to be more difficult to process validate, and so on.

3.32As illustrated in Figure 5, I believe there are a number of such trade-offs in terms of model design. Making a model easily amendable to one kind of verification/validation makes it more cumbersome to validate/verify with another kind.

3.33We first consider the relationship between input validation and verification. Here, researchers often face a practical trade-off because a successful input validation is facilitated by a direct and detailed representation of the system under investigation, but verification is easier if the model is more parsimonious. Also, the ease of verification due to model simplicity often comes at the expense of generality, since it is not clear to what extent the model applies to situations for which the (strict) assumptions are not applicable (Cartwright 2007).

3.34When turning to the relationship between verification and descriptive output validation, we again observe tension in terms of model design. Descriptive output validation produces the best results for models with many degrees of freedom, while verification is easiest for simple and parsimonious models. As in the case of verification and input validation, there is a trade-off between a more complex and better validated and a simpler, better verified model.

3.35The next relationship to be considered is that between descriptive and predictive output validation. It is very clear that there is a trade-off involved because the relationship between the two kinds of validation mimics the well-known trade-off between risk-minimization and empirical risk-minimization in inferential statistics. The more degrees of freedom we give to our model, the easier it is to calibrate it to the data we have, but the greater the risk for over-fitting.

3.36Finally, we turn to the relationship between predictive output validation and process validation, which I believe to be complementary. There are a couple of reasons for this: Firstly, one argument in favour of representing real-world mechanisms explicitly in formal models is that such models are easier to generalize than models that do not do so, both in terms of time and space. Since training a model could be considered a generalization from small data sets, models that explain in terms of mechanism should at least not perform worse when it comes to prediction. Secondly, training a model works through letting the algorithms explore patterns in the data, and these patterns are likely to be caused by real-world mechanisms. Therefore, a model that performs well in resembling mechanisms of the target should at least not perform worse in predicting the system’s future behaviour as a model that does not capture these mechanism well. Finally, real-world mechanisms are usually unobservable. And while the techniques of process validation mentioned above are certainly effective, pro-cess validation should always be complemented by other validation techniques. Predictive output validation, if feasible, certainly seems to be an excellent choice from a practical perspective.

3.37It is important to note that the trade-offs presented here are – except the trade-off between descriptive and predictive output validation – not formally proven. They are based on personal experience and logical consideration. Studying these trade-offs more formally and to clarify whether they count as simple of complex trade-offs in the sense of Matthewson & Weisberg (2008) is a fruitful area for future research to which both practising modellers and philosophers have something to contribute.

Validation and the purpose of a model
3.38Considering these intricate relationships and trade-offs between various forms of verification and validation, we must ask whether there can be a reasonable prioritization among them. If this were true, one should design a model such that it maximizes its performance in terms of this form of verification and validation and then turn to the other forms one by one, depending on their respective importance. Unfortunately, such a general ranking is not feasible. Rather, what kind of verification and validation is needed depends on the purpose of a model (Mäki 2010), and the degree of validation required depends on the fidelity criteria as introduced in Section 2.

3.39There are many purposes for modelling one could think of (see e.g. Epstein 2008). For models that are primarily geared towards the provision of adequate predictions, predictive output validation is obviously very important, yet process and input validation is only indirectly a concern. On the other hand, if a model should explain why a certain phenomenon in the past has occurred, descriptive output validation and process validation are of particular importance. In both cases, the adequate validation techniques as well as the practical design of the models differ[18].

3.40The key message here is that depending on the purpose of the model, decisions between competing designs must be made and the decision in favour of one design might entail better performance in one kind of verification/validation at the cost of a comparatively worse performance in another kind of verification/validation.

3.41There is no general rule for a concrete prioritization of the respective kinds of verification and/or validation. The intensity and kind of validation depends on the fidelity criteria and the purpose of the modellers. Yet the comparison among different models and their interpretation can nevertheless be facilitated if the design choices are made as transparent as possible and are explicitly justified and related to the purpose and the construal of the model. Here, my proposal aligns with existing frameworks for model presentation according to which the model purpose should be made explicit (e.g., Grimm et al. 2014). If researchers were very specific with regard to the fidelity criteria they had in mind when building a model, much mis- and abuse of models could be prevented.

3.42While the claim that validation should follow the purpose of the model is widely accepted, there are important exceptions. As argued by Lehtinen & Kuorikoski (2007), different disciplines have different conceptions of what counts as ‘understanding’. Based on these conceptions, they may not fully subscribe to the claim that ‘validation should follow the purpose of the model’. Economists, for example, prefer parsimonious models that can be solved analytically within the maximization-cum-equilibrium approach. This constrains the set of admissible methods and validation techniques, and results in a bias towards particular forms of verification and validation in economics (in particular towards descriptive output validation)[19]. Using explicit epistemological frameworks such as the one suggested here, may facilitate identification and overcome such biases via interdisciplinary discussion and reflection.

Some Immediate Practical Implications
4.1Two immediate practical implications for applied modelling design follow from what has been claimed in the previous sections. Firstly, there are some design principles that are at least never harmful, but frequently useful when assessing the relation between a model and reality. These are principles such as a modular modelling design and the strive for transparency and clarity in the exposition of the model. Here, the existing frameworks with regard to the functioning of models, and the epistemological framework as introduced above could be helpful. Secondly, while it may not be possible to design a model that performs very well in terms of all kinds of verification and validation, one can sometimes combine the respective strengths and weaknesses of several models via the practice of sequential modelling.

4.2Sequential modelling refers to the practice of starting with a very simple and stylized model and then building more and more complex models that are all verified by aligning them (in the sense of Axtell et al. 1996) with the previous, simpler model. In the best case, the first and thus simplest, model is amendable to analytical proofs. Usually, such simple models are purely equation-based. One can then proceed by building an agent-based model that can be aligned with this simplest model. This way, one can “transfer” some of the rigour of the simpler model to the more complex model: by showing that the more complex model behaves –for the relevant parameterization – as a simpler and well-verified model increases our trust in the functioning of this model. On the other hand, because of its increased complexity it can be validated more rigorously (see Gräbner et al. 2017 for an example and a thorough discussion of the concept). If successful, this practice allows one to appreciate the advantages of simple models in terms of verification also for the more complex models, which have their strengths in model validation.

4.3An example is provided by Henderson & Isaac (2017). The authors start with a general-equilibrium model of agrarian production that allows for an analytical solution. The model however, poorly represents the structure of modern agrarian production. To preserve the rigour of the original model, Henderson and Isaac develop an agent-based model that replicates the functioning of the original model. Thanks to its modular structure, the agent-based model can then be extended to include some essential features of modern agrarian production that are beyond the scope of the original model. Finally, the authors have a model that is a good representation of the reality the authors are interested in, but that is also verified because of its sequential construction.

4.4Unfortunately, the practice of sequential modelling is not always applicable. The system under investigation must be such that a very stylized model can be at least remotely related to this system. This may not always be the case. Furthermore, when relating the increasingly complex models to each other, one faces the problem of when one model simulates another. This has been discussed more extensively in Axtell et al. (1996) under the topic of ‘Aligning Simulation Models‘ and subsequent work. Despite its potential difficulties however, there are already a couple of examples where the practice of sequential modelling has been very successful, see e.g., Axtell et al. (1996), Bednar & Page (2007), Gintis (2007), or Henderson & Isaac (2017).

Conclusion and Outlook
5.1A number of central concepts and vocabulary from the philosophy of science have been introduced in order to equip applied modellers with the means to communicate more precisely the epistemological foundations of their models. Furthermore, the concepts and epistemological framework can be used to illustrate the various ways models can help us to understand reality. I have argued that using such frameworks is useful since they help to exemplify the different epistemological foundations of models. This way, we can more transparently justify the modelling framework we have chosen and compare the results of different models more effectively.

5.2The resulting framework was also used to distinguish and illustrate various forms of model validation and verification. The distinction between validation and verification is meaningful since not all models are directly related to reality – yet they can nevertheless be useful in a sequential model building process and should therefore be verified. We have also seen that there are different ways to relate a model to reality (i.e., to validate it) and that there seem to be trade-offs with respect to model design: some designs facilitate verification/validation in one sense, but make it more difficult in another. Which kind of verification and validation should receive priority depends on the model purpose and its construal, yet there are some design principles that are always useful and never harmful (e.g., a modular design).

5.3Based on these considerations it follows that different modelling approaches have different comparative advantages and disadvantages with respect to verification and validation. Agent-based models, for example, seem to have a comparative advantage in terms of input validation and process validation. A comparative disadvantage of agent-based models is model verification: while a great number of excellent verification methods exist, ABMs usually do not allow for the most successful verification technique: a mathematical proof, which is why they are characterized by a certain “epistemic opaqueness” (Humphreys 2009). Based on this observation, the practice of sequential modelling has been suggested. Similar to the idea of sequential modelling is that of using a plurality of models (e.g., Aydinonat 2017).

5.4Finally, I want to build on our epistemological elaborations to answer two questions mentioned in the beginning: (1) “Is verification and validation necessary?” and (2) “Is verification and validation possible?”. With regard to the first question, I cannot think of any cases where model verification should not be given high priority. There are many reasons for why we should know how our models work, which is why every model in this world should be properly verified.

5.5Validation becomes necessary as soon as we want to use a model to make informed statements about the real world (e.g., Schulze et al. 2017). This is not always the case: there are models that are not meant to be representations, or to be used for statements about real or artificial systems. For such models, validation makes no sense.

5.6Other models are hard to validated because they do not make direct statements on reality (Ylikoski & Aydinonat 2014). This is the case for ’proof-of-concept‘ models that illustrate an idea, or a causal mechanism scheme that may later serve as a building block for more complex models (see e.g., Squazzoni & Gandelli 2013; Ylikoski & Aydinonat 2014). This however, should be clarified by the modellers in specifying carefully the scope and assignment of the model, as well as its fidelity criteria. Then, validation should take place in accordance with these specifications: the kind of validation we should seek depends on the particular kind of statement about the world we want to make. So while validation might then be a rough activity (if no precise statements about the target are attempted), but is remains necessary as soon as one uses a model to make any statements about the real world.

5.7In effect, verification is always and validation often important. What about the feasibility of verification and validation? If we consider our framework as illustrated in Figure 4, verification is only concerned with the internal structure of a model. At least for simple mathematical models a nearly complete verification is often feasible. Verbal models can never be verified with certainty, and computational models reside somehow in the middle. So, while complete verification is possible only for a small subset of models, sufficient verification is a feasible and attractive desideratum.

5.8Considering validation, the situation becomes more complex. Firstly, some forms of validation are easier (e.g. descriptive output validation) while others (e.g., process validation) are more difficult. Secondly, a complete validation will always remain impossible, even if one focuses on one particular form of validation (e.g. input validation). We simply cannot perceive reality in its entirety such that we could compare the model to this complete description of the real world. Even in the century of big data (in which still many data problems prevail, see Schulze et al. 2017), there will never be the perfectly validated model, also because of the trade-offs between different validation types.

5.9Yet, the fact that complete verification and validation is impossible does not release us from the duty to strive for the best verification and validation that is appropriate for our modelling purpose, and to be transparent with regard to how we want our models to relate to reality and on how we have assessed this. Frameworks such as the one presented here hopefully facilitate this task.

Acknowledgements
An earlier version of this article has been presented as a keynote speech at the “Agent-based modelling in economics – from toy model to verified tool of analysis“ held between May 19th-20th 2017 at the ESCP Europe Business School in Berlin. I grateful to all participants for the lively discussion and the most helpful comments. I am particularly grateful to the constructive comments by Wolfram Elsner, Sylvie Geisendorf, Torsten Heinrich and Iris Lorscheid. I also benefited tremendously from the discussions at the TINT workshop “What to make of highly unrealistic models?” held between 12-13 October 2017 at the University of Helsinki and organized by Emrah Aydinonat, Till Grüne-Yanoff and Uskali Mäki. Finally, I want to acknowledge two most helpful referee reports and the useful comments by the editor of JASSS. All remaining errors are my own. This research has benefited from funds provided by the Oesterreichische Nationalbank (OeNB) under the Anniversary Fund, project number: 17383.
Notes
Its use has been encouraged by prominent outlays, including JASSS. However, it is more prominent in some disciplines (e.g. ecology), and less frequently used in others (e.g. economics). This illustrates the difficulty of introducing commonly accepted standards into a lively research community.
Some models are not meant to represent anything, and models are not the only way to represent objects (e.g. Frigg & Nguyen 2017). But as I will justify in more detail below, this paper focuses on models as means to represent a system under investigation.
For an excellent illustration of the consequences of different conceptions of ‘understanding’ see Lehtinen & Kuorikoski (2007) who study the reluctance of economists to use agent-based simulation models.
Lehtinen & Kuorikoski (2007) argue that these particular epistemological preferences of economists explain why ABMs are less accepted in the economics community: economists (to a large extent) still adhere to the idea that scientific understanding “consists of the ability to logically derive conclusions with a small set of common argumentation patterns” (Lehtinen & Kuorikoski 2007, p. 324), and these “common argumentation patterns” in economics are individual rationality and optimization, as well as systemic equilibrium. Simulation models do not have their comparative advantage in this kind of explanation (see below), which is why most economists – in contrast to many other social and natural scientists – are reluctant to use them. This account of the economic way of theorizing is descriptive, and not an endorsement of this kind of theorizing. Taking such approach to theorizing seriously reminds us to value rigour and parsimony and to question whether the complexity of a model is adequate, yet in general this kind of epistemology, which is most precisely formulated by Kitcher (1989), is not desirable in a normative sense (see also Squazzoni 2017 for a critical discussion of the policy implications of the modelling style advocated in economics).
General equilibrium models are a standard modelling approach in economics. One specifies few representative agents that maximize their utility and imposes an equilibrium restriction on the system as a whole. The classical introduction is given in Mas-Colell et al. (1995).
For criticism see e.g., Odenbaugh (2018).
Appendix: Relating the Framework with the ‘Evaludation’ Framework of Augusiak et al. (2014)
Augusiak et al. (2014) argue that the terms ‘validation’ and ‘verification’ should be eradicated because of their ambiguity. Instead, they propose the general term ‘evaludation’. I believe that – properly defined – the terms ‘verification’ and ‘validation’ are useful and highlight the difference of studying a model itself and the relation between a model and reality. The term ‘evaludation’ blurs this distinction for the sake of generality. Nevertheless, I believe the framework and the terminology of Augusiak et al. (2014) to be extremely useful for model analysis, particularly because it is well adjusted to the natural modelling cycle. However, I think it would be useful to complement it by an explicit, epistemological framework as presented in this paper.

To facilitate this task, Table 2 relates our framework terminologies to Augusiak et al. (2014).

Table 2: A clarification of the relationship between the terms used by Augusiak et al. (2014) and the verification/validation terminology of the epistemological framework introduced before.
Term from Augusiak et al.	Relation to verif/valid terms	Comment on the relationship
Data evaluation	NA	Augusiak et al. (2014) rightfully highlight this step an essential part of the modelling cycle, but it does not need to be part of an epistemological framework.
Conceptual model evaluation	Verification /Input validation	Augusiak et al. (2014, p. 125) consider this as the "assessment of the simplifying assumptions underlying a model’s design [...] including an assessment of whether the structure, [...] form a logically consistent model." This step has elements of model verification (e.g. the test of all assumptions are logically consistent), and validation (e.g. the assessment of the assumptions capture the essence of the real system).
Implementation verification	Verification	Augusiak et al. (2014, p. 125) use this step to ensure that the modelling formalism is accurate and that the computational model does what it is supposed to do. This corresponds to verification in the sense I use the term.
Model output verification	Input validation	Augusiak et al. (2014, p. 125) define the aim of this step as "to ensure that the individuals and populations represented in the model respond to habitat features and environmental conditions in a sufficiently similar way as their real counterparts.” This step involves some aspects of verification, but mostly corresponds to input validation.
Model analysis	Verification	Here, Augusiak et al. (2014) are concerned with testing the sensitivity of the model to changes in the model parameters, and the understanding of how the model results have emerged. This step is clearly about verifying the model since no link to reality is investigated.
Model output corroboration	Predictive output validation	In their final evaludation step, Augusiak et al. (2014, p. 125) seek to compare "model predictions with independent data and patterns that were not used, and preferably not even known, while the model was developed, parameterised, and verified." This is basically the definition of predictive output validation.
There are two aspects regarding the relationship that are worth mentioning: Firstly, Augusiak et al. (2014) do not mention all forms of validation that are possible. I believe that what they term “Model output corroboration” might be interpreted more broadly to capture both descriptive output validation and process validations.

Secondly, the framework of Augusiak et al. (2014) is by no means incompatible with my epistemological framework. This is not surprising given the fact that both frameworks have different, yet complementary aims. From a pragmatic viewpoint, it seems to me that if both frameworks are used jointly, every step in the evaludation procedure should explicitly distinguish between activities concerned with the model, and activities assessing the link of the model with reality, and be explicit about how the latter could be established. In Figure 6, I suggest a way to accommodate explicit epistemological considerations into the evaludation framework (thereby slightly altering the terminology of Augusiak et al. 2014), but other ways to relate the framework are certainly possible.

This paper describes the Nudge-Emergence-Diversity (NED) model, an Agent-Based Model (ABM) that represents the adoption of energy efficient technology and behaviours within a diverse population, and incorporates: behaviour-driven models of decision making; diversity of the population through rich survey datasets of shifting preferences; and the emergence of behaviours within social systems, including representation of trust-based information networks and influence across social networks.

1.2This model is in line with recent papers arguing that ABM is a very promising approach for helping to build better theories and models of energy demand and the adoption of energy efficient technology (Rai and Henry 2016). It is also in line with the thinking of recent Nobel Prize laureate Richard Thaler and his colleagues who argue that governments can benefit significantly from investing in behaviourally informed policies to nudge community behaviour in cost-effective manners, using energy efficiency as one of the success stories in this context (Benartzi et al. 2017).

1.3The case for reducing household energy use is related to the notion that there are profound impacts from human activity on the planet, which some argue is pushing the planet into a new geological era, the Anthropocene (Zalasiewicz et al. 2010). These are profound changes on the functioning of the planet and from a human perspective, the earth is now outside of its safe operating space, in at least three areas of which one is relating to climate change (Rockström et al. 2009). Among the diverse impacts of climate change, including ecosystem and species loss (Thuiller et al. 2005, Brook and Barnosky 2013), from a human perspective perhaps the most worrying concern is that without staying within the safe operating space, including on climate change, it looks difficult for global food systems to meet food demand on current projections (Conijn et al. 2018). This shows that it is imperative to reduce global greenhouse gas emissions. The residential sector accounts for approximately 30% of worldwide energy use (Swan and Ugursal 2009) and the energy sector is the largest contributor to greenhouse gas emissions in most countries (Höhne et al. 2011).

1.4There are two main approaches to reducing the Carbon Dioxide equivalent (CO2-e) emissions from the residential sector, namely through reducing household energy use (increased energy efficiency) or the adoption of renewable energy technologies. Increasing the energy efficiency of households typically requires both behaviour change and technology change. Residential adoption of more energy efficient technology or change of consumer behaviour is an important strategy for mitigating climate change. This is in the context that human-induced CO2-e emissions from residential energy use have been estimated to represent 11% of total CO2-e emissions in the European Union (Drummond and Ekins 2016), and 21% of CO2-e emissions in the United States (Estiri 2015). In a status quo scenario with a projected growing population, Australia’s CO2-e emissions from residential energy use are expected to grow by 38% by 2050 (Hetherington et al. 2015). In fact, it has been found that without energy efficiency improvements in the past, over a 30 year time period the Organisation for Economic Cooperation and Development (OECD) nations would cumulatively have used 49% more energy than they used as of 1998 (Geller et al. 2006).

1.5Energy efficiency in households particularly relates to lighting and appliances, refrigeration and Heating, Ventilation, and Air-Conditioning as well as water heating. It has been estimated that in Australia, the following was a breakdown of residential overall residential energy use: Heating, Ventilation, and Air-Conditioning 40%, water heating 21%, lighting 6% and appliances including for refrigeration and cooking 33% (Australian Government 2013). In many countries, there are policies in place to promote the uptake of energy efficient technologies. For example, the OECD recommends raising awareness of energy efficient technology, and education of the public about the need for environmental action. The OECD also recommends grants and subsidies focusing on low-income households (OECD 2014). But the question is, what works when promoting the adoption of energy efficient technology and what doesn’t work. Ultimately, the adoption of energy efficient technology by households involves individual consumer choices; a process subject to a complex sets of factors and relationships that is not well-represented by the rational choice model of human behaviour whereby which a person weighs up benefits and costs of different options and maximises utility (Frederiks et al. 2015). To be precise, this type of consumer choice is subject to the usual behavioural tendencies, such as being swayed by social comparisons, being loss and risk-averse, tending to favour status quo over change, and wanting to achieve a smaller set of goals rather than evaluating options more holistically (Frederiks et al. 2015). Furthermore, it has been found that the preferences can vary considerably in a population and that the types of criteria adopted depend strongly on the type of technology that is chosen; for example, thermal comfort is the most important factor for Heating, Ventilation, and Air-Conditioning systems, but the light quality is the most important factor for lighting. In fact, this highlights an important aspect of consumer choice here: energy efficiency or even financial aspects are often mere secondary factors.

1.6There is extensive research on the factors that household decision makers consider when they make decisions whether or not to adopt energy efficient technologies in their homes. For example, when households consider purchasing Light-Emitting Diode (LED) lighting, they may consider the level of illumination and the ability to render colours naturally, the expected life of a bulb, the toxicity of materials, the total harmonic distortion (a technical term relating to electricity supply), the temperature emitted from the bulb and the overall environmental impacts of the lighting technology (Aman et al. 2013; Di Maria et al. 2010; Khan and Abas 2011; Hicks and Theis 2014). When households consider the purchase of an Heating, Ventilation, and Air-Conditioning system, they may consider the level of improvement in thermal comfort, the level of inconvenience of making the change, the expected increase in the resale value of the property, any disturbing noise from the system, or any financial issues such as split incentives (Noonan et al. 2013; Wilson et al. 2015; Chua et al. 2013). There are also behavioural tendencies influencing the adoption of technology (Frederiks et al. 2015), such as the free-riding effect (trying to gain benefits without paying), variable trust in information sources (seeking judgments from trusted sources), and availability bias (drawing on knowledge or information that is easily available). Furthermore, how decision maker(s) in a particular household make their choice is highly variable depending on the particular preferences. Thus, the process of adopting technology ought to be modelled in a way that considers diversity in the population, social influence, influence from information flows, and ultimately how these factors play out at an individual decision maker scale, but create emergent outcomes at an aggregate scale, and ABM provides such a modelling framework (Rai and Henry 2016).

1.7The ABM described in this paper has been named NED after these functions, i.e. N for “Nudging” to reflect the representation of behavioural science, E for “Emergence” to reflect the representation of aggregate outcomes from a complex ecosystem of agents, and D for “Diversity” to reflect the representation of a diverse community.

1.8In this paper, the justification, design, implementation and application of the NED model are described. First the context of the study will be explained, then other similar ABMs are reviewed, subsequently, a description and justification of the model will be described, and then its application will be showcased in one case, followed by a discussion about how to use the model, limitations, and potential for improvements.

The Use of ABM to Describe Innovation Diffusion
2.1Innovation diffusion modelling, first introduced by Rogers (1962), is a field of research which arose out of the analogy between the physical process of particle intermingling thereby allowing heat transfer, and the socio-technical process by which technology is dispersed through a population of humans, with a particular focus on the role of communication. For years, innovation diffusion modelling was based on the use of equations, such as the epidemic model (Gupta and Jain 2012), the logistic model (Gruber and Verboven 2001), or the Bass diffusion model (Bass 1969, 2004). Equation-based models have some limitations, however, as was observed and noted for example by Higgins and colleagues (2011, 2014). Even with highly refined equations based models, whilst very useful and pushing the boundaries of what is possible, it still struggles to adequately represent complex decision rules, full heterogeneity in actor attributes, the role of multiple actors types and social networks (Higgins et al. 2012). Faced with these limitations, Moglia and colleagues reviewed alternatives for overcoming them and identified that ABM with a socio-psychological foundation is a viable alternative (Moglia et al. 2017). Furthermore it can be argued that ABM has the same limitations of all models because prediction is always conditional, i.e. subject to the conditions set out in the model (Boschetti et al. 2011). Therefore, it is suggested that ABM is explored as an alternative to equation-based diffusion modelling of technology diffusion processes in particular in order to support ex-ante policy assessment in areas such as when wanting to promote energy efficient technology.

2.2ABM is a type of computational model used for simulation and which emerged out of the research fields of Artificial Intelligence and Cellular Automatons. ABM allows for software representation of agents’ dynamic behaviours and decision making in interaction with each other and with their environment (Gilbert and Troitzsch 2000; Perez and Batten 2006). ABM has been used in a diverse number of topics, including archaeology, biological sciences, economics, ecology, electricity market analysis, financial analysis, social science, transport systems and water management, among others (Macal 2016; Macal and North 2005; Moglia et al. 2010). More recently, ABMs have been proposed as a particularly suitable alternative for describing innovation diffusion processes in the energy and resource efficiency context (Rai and Henry 2016; Moglia et al. 2017).

2.3The modelling of innovation diffusion using ABM is growing in maturity, as indicated by the review by Kiesling and colleagues (2012). In addition, it is noted that if calibrated and when compared to a more standard approach for describing innovation diffusion, i.e. equation-based models, ABM has similar predictive capacity (Mao et al. 2015) but greater flexibility in the ex-ante assessment of policy options as illustrated by Sopha and colleagues (Sopha et al. 2017). Examples of existing ABMs applied to the energy efficiency context are explorations of the adoption of hybrid electric vehicles (Tran 2012); alternative fuel vehicles (Zhang et al. 2011); biomass fuels (Günther et al. 2011); wood pellet heating systems (Sopha et al. 2013); natural gas vehicles (Sopha et al. 2017); alternative fuels (Vliet et al. 2010); and commercial buildings retrofits (Marquez et al. 2013).

2.4The models by Sopha and colleagues (2013) are particularly promising as they consider an advanced socio-psychological model of household decision making based on the Consumat theory, yet they also lack the wider range of agents that contribute to the adoption process, i.e. information or sales agents. Our model is similar to that by Sopha et al. but slightly adjusts the Consumat decision-making algorithm and also introduces actions by sales agents and information agents.

2.5Another related model, the Community Energy Demand Social Simulator (CEDSS), was developed by Gotts and Polhill (2017) with very similar aims to the NED model. The household decision making in CEDSS is based on goal-framing theory where householders focus either on hedonic, egoistic or biospheric goals and explore the full market of products rather than individual products separately. CEDSS focuses primarily on describing householder decision making and not so much on additional agent types. It has also been shown that the way that the goal-framing theory is deployed can lead to significantly different implementation and results, as described by Polhill and Potts (2017). This raises concerns about the application of ABM and highlights the need to be careful in the specification of decision-making models.

The Agent-Based Model
3.1This section describes the model using the Overview-Design concepts-Details (ODD) protocol which has been proposed as a standardised protocol for reporting ABMs (Grimm et al. 2006; Grimm et al. 2010).

Purpose
3.2The purpose of developing this model is to describe ‘the uptake of low carbon and energy efficient technologies and practices by households and under different interventions’. There is a particular focus on modelling non-financial incentives as well as the influence of social networks and the decision making by multiple types of agents in interaction, not just households.

Implementation
3.3The model has been implemented in NetLogo 5.3.1 (Wilensky 1999).

3.4To promote usability, the principle for the model is to allow the user as much flexibility as possible in exploring assumptions and sensitivity to model parameters through the user interface.

3.5The modelling has been informed through a co-design process whereby we have involved the potential users of the model as collaborators in the research project. The potential users we have involved are at the Office of Environment and Heritage which is part of the New South Wales (NSW) State Government.

3.6The model co-design was carried out by embedding collaborators in ongoing project team meetings, involving other collaborators in regular discussions about iterations of the model with presentations and feedback sessions. The co-design can best be described as group model building, as described by Hovmand (2013). Vennix (1996) specifies four distinguishing factors of group modelling and our approach is based on:

Firstly, the core issue was specified based on learning from previous efforts at building innovation diffusion models to address a known user need. In previous studies with the collaborators, innovation diffusion models were based on equation-based approaches (Higgins et al. 2011, Higgins et al. 2014).
Secondly, an unstructured group process was adopted based on regular team meetings and ongoing conversations about data and assumptions. This was supported by collaborators having good working knowledge of ABM based on previous studies and their own research.
Thirdly, the process was first focused on the informal causal map to generate a shared understanding, which eventually allowed the team to move towards a formal computer simulation model. This learning process was based on iterations of presentations and feedback sessions.
Fourthly, the team started with a relatively blank slate with no preconceived model. However, the approach was informed by previous modelling efforts, and quite quickly the team settled on the Consumat approach as a meta-framework for modelling household decision making.
3.7Throughout the coding of the model, efforts have been made to attempt to ensure that there are as few errors and defects in the code as possible. This has been done by means of unit testing during coding, i.e. all methods have been tested to explore outputs individually to ensure they do what they are expected to do. Secondly, the developer, as well as potential users, have been running the simulation system to explore anything that looks odd, and that the system produces accurate representations. In other words, whenever any unexpected results are reported or found, attempts have been made to verify whether this is a true representation of the conceptual model or whether it is the outcome of a software bug. Throughout development, numerous bugs have been removed, and hopefully, there are none left.

State variables and scales
3.8The model has been developed in interaction with potential users through the mapping of a set of interventions to increase the penetration of energy efficient products within a community. By mapping out potential interventions we have identified three types of agents to represent in the model as per Table 1. State variables are shown in Table 2 to 5. In addition to the agents described in Table 1, technologies are described representing energy-efficient products, and their alternatives. Therefore, there are two types of technologies for which the attributes are shown in Table 3.

Table 1: Agent types
Agent type	Role
Household	Residents make decisions about whether to adopt an energy-efficient product.
Sales agent	Sales agents may sell energy-efficient products, sometimes instigated through subsidies. Sales-agents are assumed to primarily focus on maximising profits.
Information agents	Information agents are those who provide recommendations to households on whether to purchase an energy efficient products. These include retailers, state government, tradespeople, builders and media sources such as TV home improvement programs and online forums (Podkalicka 2018; Office of Environment and Heritage NSW 2014b; Office of Environment and Heritage NSW 2014a).
Table 2: State variables of households, i.e. each household has values on these attributes
Household variables	Description	Comments
ID	An integer	A unique number to represent the agent
Dwelling type
Detached house, Apartment / Unit / Townhouse, Semi-detached or Terrace, or Other.	User-specified to reflect knowledge or data describing the target geographical area.
Household type	Type of household, as per household typology.	
Location	Coordinates on the map, representing a physical location.	Currently randomly assigned. However, if the geographical locations of households are known, this can easily be added as a household variable and mapped in the GIS component in the user interface.
Personality	A normalised value between 0 and 1 as per the Consumat theory (Jager and Janssen 2012).	Responses to questions in a household survey that reflect personality are used to calculate a ‘personality’ score.
Financial vulnerability	A ‘financial vulnerability’ score, which is normalised to a value between 0 and 1.	Based on the household survey, i.e. responses to questions that reflect financial vulnerability are used to calculate.
Preferences	A set of eight numbers between 0 and 1, normalised so that the total score adds up to 1.	Weights associated with each of the performance criteria. Based on the household survey, i.e. responses to questions that reflect preferences.
Peers	A number of peers (i.e. a list of their IDs)	Describing the household social network. Initialised based on a specified social network. This is static as it would otherwise be computationally too expensive to run the simulations and a static network is considered an adequate approximation.
Information source profile	For each of the information sources, a value 0 or 1.	This denotes which of the information sources the household agent seeks recommendations from. Based on responses in the household survey.
Technology ownership	A zero or a one to indicate ownership. Plus another number to indicate the age (in years) of the associated product.	Ownership of an energy efficient product (denoted by 1), or a non-energy efficient product (denoted by 0). Also, the age of the product. Ownership is dynamically updated and initialised based on surveys or expert opinion. The age of the technology is assigned based on a probability distribution, as per an input file.
Decision profile (dynamically evaluated in the simulation)	Mode of decision making, i.e. Inquire, Imitate, Repeat or Optimise	As per Consumat theory (Jager and Janssen 2012). Assigned dynamically in the model on the basis of evaluated satisfaction and uncertainty.
Satisfaction, i.e. a value of 0, 1, 2 or 3	The fulfilment of three satisfaction criteria.
Uncertainty, i.e. 0 or 1	Dynamically determined based on inconsistency in criteria fulfilment.
My-performance, i.e. a value between 0 and 1.	As per Equation 1
Social needs satisfaction, i.e. a value between 0 and 1.	As per Equation 2
Local-adoption-rate	The adoption rate of the energy efficient product within their friends’ network. Updated regularly.
3.9In Table 3, the relative performance of the technologies is specified by the user within input files. The input files describe how the performance factors change over time. These can be estimated based on literature, survey and/or expert opinion. The performance values are normalised values between 0 and 1, where 0 is considered ‘completely inferior to the alternative’ and 1 is considered ‘completely superior to the alternative’. The sum of the performance values for the two types of products add up to 1. If for example at a certain point in time, the upfront cost of the Energy Efficient (EE) technology is $100 and the upfront cost of the OLD technology is $50 then the Non-Energy Efficient (referred to as OLD) technology performs twice as well as the EE technology. Converted to performance attribute values, this translates to a value of ~0.67 for the OLD technology compared to ~0.33 for the EE technology. A subsidy for EE that would reduce the price from $100 to $75 would change the performance value for the EE product to 0.4 and the performance value for the OLD product to 0.6. Currently, the model only describes the choice between two types of technologies (EE: energy efficient, and OLD: not energy efficient). The state variables of technologies related to a large extent to the performance factors of the technologies, i.e. issues that have been identified as important within a literature review (Moglia et al. 2017).

Table 3: State variables of technologies
State variable	Description
Price	People tend to be influenced by monetary considerations which in turn are influenced by socio-economic factors (Hall et al. 2013). The upfront price of a product is particularly important because energy efficient technologies tend to come at a higher initial cost and access to capital can be an important limiting factor in the adoption process (Wilson et al. 2015).
Return on investment	
Ongoing cost	
Aesthetics	Aesthetics and taste anxiety are common drivers for home renovation or upgrade decisions (Rosenberg 2011). The influence of aesthetics, however, vary depending on the type of product. For example, for lighting, aesthetics relates to the ability to render colours naturally, and the level of illumination (Aman et al. 2013). Importantly, the perception of light quality, based on hearsay and experience, is likely to be as important as the actual light quality.
Comfort	Some energy efficient products are associated with greater reported home comfort, especially if this comfort can come with less guilt about using energy and emitting greenhouse gases (Chua et al. 2013, Wilson et al. 2015).
Resale value	Energy efficient products may make the property more attractive and thus are sometimes believed to create higher resale values (Noonan et al. 2013).
Electricity use	Not everyone is motivated by energy savings and environmental benefits, but some certainly are and this is seen as a function of environmental attitudes and awareness (Hall et al. 2013: Liu et al. 2013; Newton and Meyer 2013)
Environment – other	There are also other environmental impacts of products beyond greenhouse gas emissions, for example, some lighting types emit levels of mercury (Hg) which have been banned in some countries, but the sale of these persist in other locations (Aman et al. 2013).
Proportion of energy use	This represents on average how much of a household's energy is being used by the particular product’s end-use category. This information can be sourced from government websites or industry sources (Platinum Electricians 2018).
Technology efficiency	This represents the proportional reduction of the household energy use (within the end-user category) based on adopting the energy-efficient variety. This information can be sourced from government websites or industry sources.
Probability of “end-of-life” (EOL) as a function of age	This is the probability of a product being at the end of its productive life as a function of age in years. Different technologies have different ageing patterns and expected productive lives so this is specified for each product type. This can be established based on expert opinion or informed by manufacturers’ specifications etc.
Table 4: State variables of sales agents
State variable	Description	Change
Records of sales success and failure	Track record in selling energy efficient products to allow appropriate updating of the sales strategy.	Dynamic
Expenses	Expenses when purchasing and selling the energy efficient product.	Dynamic
Income	Income associated with selling the energy efficient product.	Dynamic
Sales price	The price at which the sales agent will sell the product. This is updated based on the sales track record and estimated return on investments.	Dynamic
Administration cost factor	The cost of administering the subsidy scheme. In the context of New South Wales, this is the Energy Savings Scheme (NSW Government 2018). Default value: 1.05 i.e. 5% on top of price estimated.	Static
Cost of sales attempt	The cost of an attempt to sell the product, regardless of success.	Static
Purchasing discount	The discount that the sales agent could receive when purchasing the product. Default value: 0.15, i.e. 15% discount. Based on expert opinion.	Static
Table 5: State variables of information agents
State variable	Description
Preferences	A set of normalised weights (between 0 and 1 and adding up to 1) associated with the performance criteria: price, aesthetics, electricity use, environmental issues, comfort, the return on investments, ongoing costs, and impact on resale value. These are based on expert opinion or survey and are entered by the user through an input file.
Recommendation	Evaluated dynamically on request based on a choice model equation to estimate the probability of recommending the EE product.
Process overview and scheduling
3.10The process of the model is conceptually described in Figure 1.

 
Figure 1. Conceptual description of simulation process (adapted from Sopha et al. 2013).
Household agent decision making
3.11Modelling the household decision making is a two-step process. Firstly, the household is only considering purchasing a product in certain circumstances. Secondly, once the household considers purchasing a product, the approach for choosing which product to buy is determined by the Consumat theory. For the first part of this process, there are two decision trigger points, as shown in Table 6.

Table 6: Decision trigger points
Decision trigger points	Description
Product at end-of-Life	When the product (i.e. hot water system etc.) has reached the end of its life, the consumer will consider purchasing a replacement.
Being approached by sales-agent	In each time period, sales-agents will randomly contact a proportion of the population and attempt to sell an energy efficient product. This does not always trigger a decision point, as described below.
3.12Once a household agent initiates the decision making process, the process follows the Consumat theory which is based on social psychology whereby the mode of decision making hinges on two issues, i.e. firstly the level of satisfaction and secondly, the amount of uncertainty, i.e. the amount of cognitive effort required in making a decision. Depending on high and low needs satisfaction, and high and low uncertainty, the four modes of decision making are as follows. The level of needs satisfaction and the level of uncertainty when a household agent makes a decision is in turn based on three criteria, Existential Needs Satisfaction (see Equation 1), Social Needs Satisfaction (see Equation 2) and Primary Focus Satisfaction, i.e. whether the highest priority performance > 0.5 as this means that the option outranks the alternative (the performance values are normalised in order to add up to 1). These criteria are thought to be satisfied when the value is above 0.5.

Existential Needs Satisfaction (i)=(?j=1to8wi,j·pi,j)+Behaviour-Adjustment
(1)
Social Needs Satisfaction (i)=(ai·u)+(1-u)·(1-ai)
(2)
Behaviour-Adjustment=Delta(hassle)+Delta(discount)+Delta(free)+Delta(word-of-mouth)+Delta(status-quo-bias)
(3)
3.13Here,

i refers to household number i,
w(i,j) refers to the preference weight of household i regarding performance factor j.The weights add up to 1.
pj refers to the performance of the energy efficient product against factor j. This is a normalised number between 0 and 1.
ai refers to the personality value of household i
u refers to the adoption rate of energy efficient products.
3.14The behaviour adjustment factors and their values are further described in the supplementary materials. The choice of the decision mode is based on how many criteria are being fulfilled, which is an adaptation of the Consumat theory, as per Jager and Janssen (2012). The Consumat meta-theory of decision making considers existential needs satisfaction and social needs satisfaction, as well as an evaluation of uncertainty in expected outcomes. After deliberation within the team, it was thought that it is beyond householders’ consideration to consider uncertainty in statistical expectations, but within their capacity to consider inconsistency between social and existential needs satisfaction, and other criteria. We also wanted to consider a crowding out effect, where particular preference is given to the householder’s most important issue. Therefore we consider that satisfaction and uncertainty are based on the overall weight of the three criteria, in the following manner: 1) no criterion fulfilled: unsatisfied and certain, 2) one criterion fulfilled: unsatisfied and uncertain, 3) two criteria fulfilled: satisfied and uncertain, 4) three criteria fulfilled: satisfied and certain. The decision modes are as follows.

Repetition: Satisfied and certain. Repeating the behaviour of the past, i.e. if a household agent already has an EE product, the household agent will then also upgrade with an EE product, and vice versa.
Imitation: Satisfied and uncertain. Copying the behaviour of a household within the social network. Only friends that are “satisfied” are considered. If the household has no satisfied friends, then the household will consider the adoption rate in the broader community, i.e. if the uptake of EE is 25% then the likelihood that a household will adopt EE is 25%.
Optimisation: Unsatisfied and certain. Choosing the product with the highest overall performance, i.e. the weighted sum of product performance and individual priority weights, plus behavioural factors.
Inquiry: Unsatisfied and uncertain. Seek recommendations from the information sources that the household agent will consider (as per attributes in Table 2). A probability p of adopting EE is calculated as the weight of recommendations for EE divided by the weight of recommendations for EE and OLD.
Information agent decision making
3.15Information agents provide recommendations to households (i.e. ‘you should buy an energy efficient product’, etc.) when households are in the ‘inquiry’ decision mode. In the default model, there are nine types of information sources, i.e. family and friends, TV home improvement programs (based on expert opinion, two different types of shows are included due to their current dominant position in the Australian market, i.e. Grand Designs and The Block), retailers (two included), tradespeople, online forums, builders, government information sources; these are chosen and parameterised based on information in industry reports (Office of Environment and Heritage NSW 2014b, 2014a) and academic papers (Rosenberg 2011; Podkalicka 2018). To determine which recommendation to provide, information agents have the same type of attributes as households regarding prioritising different performance measures (see Table 5) on performance measures for each of the technology options to calculate the probability of recommending an EE product based on a discrete choice logit model:

P(recommendation=EE)=e(k·µ)e(k·µ)+e(k·(1-µ)
(4)
3.16Here, µ is the weighted performance of the EE products, and where the weights are the information agents’ priorities, as per Table 2. k is a weighting factor which should ideally be fitted based on choice experiment data; however in the absence of this data the parameter has been set to 5 so that the equation reproduces what is considered realistic behaviour.

Sales agent decision making
3.17Sales agents represent actors who will contact households directly to attempt to get them to upgrade to an energy efficient type of product. In the context of the Energy Savings Scheme in New South Wales, these may be what are called the ‘aggregators’ who create energy saving certificates on behalf of clients, and who thus can claim the financial reward of doing so (each certificate can be claimed at a price which is adjusted on an ongoing basis). However, sales agents do not necessarily need a subsidy from the government, but may also simply be able to create a financially viable business by purchasing discounted products and having an acceptable level of success in their sales activities.

3.18In each time step (as per Figure 1), sales agents contact a certain number of households and attempt to sell an energy efficient product. In the model, a household will make a decision based on the following rules:

If the household does not already own an energy efficient product, and if the existing non-energy-efficient product is past its half-life (here defined as when half of all products have reached the end of their useful life), the household will consider purchasing an energy efficient product (i.e. initiate a decision-making process). This rule is based on the acknowledgement that householders may sometimes, in some circumstances, consider replacing a product even when it isn’t broken, for lifestyle reasons or due to a perceived opportunity to “get a good deal”.
In this context, the household will only initiate a decision making process for purchasing an EE product if they believe that a good deal can be made that will soon be unavailable, i.e. if it is sold either at or below current market price. Once the decision-making process has been initiated, all the usual performance issues will be considered as per household preferences (see Table 2 and 3).
Then, if the household escalates to the decision making process, the eventual decision will be on the basis of the Optimise decision mode, i.e. on the basis of existential needs satisfaction (Equation 1), but with adjustment for the price provided by the sales agent, and with the usual behaviour-adjustments.
3.19Furthermore, in each time step, each sales agent will update their attributes and decision rules on the basis of the assumption that they will act as financial rational actors and maximise their profits (which is consistent with indications from qualitative research in the project, from medium-sized to large businesses; but not appropriate for smaller companies):

Calculating the success rate, i.e. the number of successful sales calls divided by the total number of sales calls.
Calculating the return on investments by dividing the profit with costs.
Adjusting the outreach (i.e. the number of sales calls made in each time step), on the basis of:
If more than 3 times target return on investments, then grow this number by 25%
If more than 1.5 times target return investments, then grow this number by 10%
If more than target return on investments, then grow this number by 1%
If making a loss, then halve this number
Adjusting the sales price on the basis of an expected success rate and on the basis of ensuring a target return on investments (by calculating the expenses ‘per sale’ and choosing a price at the 25% mark between the estimated cost and the market price of the system).
Design concepts
3.20Key aspects of the NED are mapped out and described, as per Kiesling et al. (2012), in Table 7. This table has a number of concepts and notions that are not described in detail here but which are described in more detail in the earlier part of the paper.

Table 7: Model features in NED
Model features	NED design feature
Method for agent adaptation	Household agents make decisions using decision rules, as per the social psychology approach based on the Consumat theory (Jager and Janssen 2012; Janssen and Jager 1999; Jager, Janssen and Viek 2001).
Emergence	The Consumat model allows for decision rules, two of which enable a degree of emergent behaviour due to interaction with other agents. These two decision rules are imitation and inquiry.
Fitness	Households calculate the fitness of adopting a technology based on their perceived capacity to fulfil social and existential needs.
Interaction	Households interact with each other through imitation, inquiry and social comparison. Social needs evaluations are dependent on the behaviour of other households. In addition, households are influenced by information agents in the inquiry decision mode and sales agents trigger household decision points.
Level of social influence (micro, meso or macro)	There is an influence at the micro-scale (via connected friends), mesoscale (via aggregate measures within groups of friends), and macro-scale (via aggregate measures at the community level). Imitation occurs at the micro-level. The user can provide input through a ‘slider’ to decide to what extent social comparison occurs at the mesoscale or the macro-scale. The default is set to the mesoscale.
Social network typology	There is a social network connecting household agents. The user can choose between friends’ network based on a small world network, random network, or a spatially based network (i.e. neighbours). The social networks are based on synthetic data generated using various algorithms such as the: small-world networks (Watts and Strogatz 1998) or scale-free networks (Barabási 2002).
Consumer heterogeneity and collectives	A household survey was used to describe heterogeneity in 1) priorities; 2) level of financial vulnerability; 3) types of the households as per typology; 4) preferred information sources used.
Setup and initialisation
3.21The model is being set up in a process that involves 1) user inputs to choose parameters and model settings, 2) reading input files, 3) creating agents to represent households, information agents, and sales agents, 4) creating a social network between households, and 5) creating technologies and assign their attribute values as per input files.

3.22The number of household agents of different dwelling types and household types (with categories as per Table 2) are defined in an input file, typically representing census data of the target area. An example of the information structure is shown in the supplementary materials.

3.23When a household agent is created, it receives its attributes copied from the survey responses, currently a database of 954 responses (Office of Environment and Heritage NSW 2014a). Rather than providing the raw survey data, this file represents the result of statistical analysis of the survey data. Python scripts were used to process the initial survey responses into a format that is appropriate as an input file for the simulator. The assignment of attributes is carried out as per Figure 2. There are also input files to specify the attributes of the information and sales agents (examples provided in the supplementary materials).


Figure 2. Initialisation of household agents. n(i,j) is the number of households of household type i, and dwelling type j as per input file.
Input
3.24A key driver for the model dynamics is the technology performance which is specified through input files. Due to limitations in space required and to illustrate the approach, we only focus on hot water systems here. The values on technology performance of hot water systems are shown in Table 8.

Table 8: Technology performance input
Performance metric	Start	End	Data source
Price	0.18	0.40	Consumer websites in Australia put the price of a solar hot water system in the range of $3,000 - $7,000 fully installed (Choice 2017); whilst an alternative system would cost $450 - $1,800 (www.australianhotwater.com.au 2017).
Aesthetics	0.50	0.50	It is assumed that there are no discernible differences between systems in this respect.
Electricity use	0.71	0.90	Numbers on annual electricity use from Moore et al. (2017). 15,260 MJ/y for an electric storage system; and 6,104 MJ/y for a solar electric system. It is assumed that these numbers will improve over the time frame.
Environmental issues (other)	0.50	0.50	It is assumed that there are no discernible differences between systems in this respect, as there have been no such findings reported.
Comfort	0.55	0.65	Expert opinion. To be estimated using surveys in the future. This represents the notion that using hot water without the added guilt of spending much money or overly polluting the environment makes for a more comfortable home.
Long-term cost	0.58	0.80	Calculated based on initial price and electricity use plus $0.25 per kWh (Australian prices) and the cost over a 12-year time frame; as 12 years is an approximate expected life of a hot water system.
Ongoing cost	0.71	0.90	Assumed to be perfectly aligned with electricity use.
Impact on resale value	0.52	0.55	Expert opinion. To be estimated using surveys in the future.
3.25Furthermore, based on conversations with experts and review of the literature, we adopt a set of assumptions that relate to hot water systems and to the interventions to attempt to increase adoption rates; as shown in Table 9.

Table 9: Input settings
Input setting	Explanation
Initial adoption rate, i.e. p-start	The adoption rate at the start of the simulation is 21% based on data from Beal et al. (Beal et al. 2012). It is noted that this is data from Queensland rather than New South Wales (i.e. a similar jurisdiction).
Urgency of replacement	It is assumed that when a hot water system breaks down, due to the urgency of the situation, households will not analyse the problem in detail; and thus we set the uncertainty as high which will trigger the inquiry or imitate modes of decision making. The only time, for the case of hot water systems, that a decision will be made through careful evaluation (optimise mode) is when being approached by a sales agent.
Promoting solar hot water systems amongst plumbers	Working with plumbers to achieve a greater rate of recommendations of solar hot water systems, thus for this scenario, we put the tradespersons’ priorities to be: 30% price, 50% electricity use, and 20% comfort.
Subsidy	Providing a 20% subsidy on all purchases of solar hot water systems.
Energy savings scheme certificates	Making a subsidy available to sales agents via energy savings certificates (say at $20, or $30 per certificate). The idea is that this prompts sales agents to be proactive in their attempts to sell solar hot water systems to the community.
Social network	For the purposes of this paper, a small world social network is employed, generated using the Kleinberg model with a clustering component set to 2, as is considered to be optimal (Easley and Kleinberg 2010).
Awareness	It is assumed that everyone knows about solar hot water systems as an option so the AwarnessImpact is set to 0 (meaning that awareness is 100% from the start).
Time frame of simulation	We have chosen to simulate the adoption of technology over the time frame of 2017-2047. We recognise that this means that much will change during this time frame and that it is unlikely that things will stay as they are described in the model. However, we also like a longer time frame in order to highlight the long term benefits of decisions being made now.
Sub-models
3.26An important aspect of the model is to calculate reductions in carbon emissions, and therefore the carbon accounting component estimates reductions in carbon emissions. For example for the solar hot water systems, the assumptions are shown in Table 10.

Table 10: Carbon accounting parameters
Parameter	Explanation
Proportion of household energy use	Hot water is assumed to account for 21% of the household energy use (NSW Government 2016).
Reduction in energy use	A solar hot water system is assumed to reduce energy use for producing hot water by 60% (Moore et al. 2017).
Household energy use per year	An average household in New South Wales, Australia, is assumed to use approximately 5,920kWh per year (ACIL ALLEN Consulting 2015).
Emissions factor	For New South Wales the emissions factor is set to 0.86 kg CO2-e/kWh (Australian Government 2014).
Emissions factor gradient	It is assumed that with the gradual installation of renewable energy and other cleaner energy sources, the emissions factor will continually drop at a rate of 0.01 per annum.
Scenario Results
4.1To illustrate the use of the model, we will report on the following explorations:

Testing the model for stability: does the model have significant amounts of randomness embedded or does it produce similar results every time?
Sensitivity analysis to policy interventions: what interventions are more efficient in increasing adoption rates?
Testing the stability and validity of the model
4.2Running the model multiple times with a baseline scenario, i.e. with no intervention, helps to explore whether the model provides repeatable results. As there is a range of stochastic aspects of the model, it would seem likely that different simulation runs would provide significantly different results but this does not seem to be the case, as illustrated by Figure 3.


Figure 3. Baseline scenario as Box-Whiskers Plot based on 50 simulation runs. For each year, the plot indicates the median adoption rate with a line and then the 25% percentile, 75% percentile, in a box, as well as minimum and maximum values.
4.3The average adoption rates of 50 simulation runs each for four different types of social network, are shown in Figure 5 which shows only limited variability between runs. There are some systematic differences depending on the underlying social network structure however with slightly higher rates of adoption in the scale-free social networks. We believe this relatively small difference in results arising from variable social network typology is due to adoption rates being fairly homogenous across the population. Other observations from the simulations are:

Sales agent never gets activated in this baseline scenario because the return on investment never gets above the critical threshold as the certificate price is $0 so the sales agent struggles to generate profit.
Adoption rate curve seems to follow what will have to be assumed the ‘middle part’ of an S-curve (standard in innovation diffusion), which is consistent with starting at a starting adoption rate of 21% and not reaching a plateau during the simulation time frame.
4.4It is unfortunate that there is no accessible longitudinal data on uptake of solar hot water systems available in Australia in order to validate the model against. In terms of validation, only limited comparison with historical data is possible but a paper by Ferrari et al. (2012) with data on sales of solar hot water systems shows that the 35% of hot water systems sold in 2010 in New South Wales were solar hot water systems. This is consistent with the linear trend in the sales rate (i.e. the proportion of new products being solar hot water systems) extracted from the model when the trend in the sales rate is extended back in time (see Figure 6). This is promising, considering none of the parameters in the model were calibrated to fit with historical data. Explorations of the parameter space is warranted, however full sensitivity analysis is beyond the scope of this paper due to the complexity of the model. Gotts and Polhill (2017) suggest a suitable approach for complex models such as these, i.e. 1) enter parameter values which seem to reasonably fit with empirical data, 2) systematically vary parameters that seem likely to most influence results. The sensitivity analysis can easily be supported in the NetLogo BehaviourSpace tool, and through the relatively intuitive user interface, as is illustrated with the sensitivity analysis for the k weighting factor in Equation 4 (representing approximately the inertia in getting information sources to recommend energy efficient technologies). See Figure 4 for the result of this sensitivity analysis.


Figure 4. Sensitivity analysis showing the result of 50 simulation runs for each k weighting factor setting between 2 and 10. This factor represents the inertia in information sources recommendations of energy efficient technology. There are error bars present but not displaying clearly due to the small amount of variation between runs.

Figure 5. Adoption rates from 50 simulation runs for each social network setting, with the baseline case of no interventions in the case of using a Small-world, Scale-free, Spatial and Random social network. X-axis: years. Y-axis: Adoption rates of solar hot water systems, as a proportion of all hot water systems, including confidence intervals around each data point (i.e. the width of the confidence intervals are +/- 1.96 standard errors).

Figure 6. Sales rate (proportion of all sales being solar hot water) as a function of time. X-axis: years; and Y-axis: the proportion of hot water systems being solar hot water systems. A trend line has also been added to illustrate projected sales rates, going backwards in time. Note that there is only limited variation between runs using this model as illustrated in Figures 4 and 5.
Evaluating interventions
4.5The types of interventions that the model could explore include: 1) activating sales agents to attempt to sell more energy efficient products to the community, 2) influencing retailers and other key actors such as tradespeople to recommend the adoption of energy-efficient products, and 3) providing direct subsidy to community members for purchasing energy efficient products through cheap loans and/or subsidies. Specifically, to illustrate the use of the model, here we describe a couple of interventions to promote the adoption of hot water systems, including:

The Energy Savings Scheme (NSW Government 2018) whereby so-called aggregators apply for energy savings certificates after installing, improving or replacing energy savings equipment. They may choose to proactively target householders to increase sales of energy efficient products and they may also choose to use some of the energy savings certificates to reduce the price of products. We explore three settings on the energy savings certificates, i.e. $0, $20, and $30.
Working with plumbers to increase the rate of recommendations of solar hot water systems. The plumber is often contacted by householders when a hot water system breaks down. In this scenario, the recommendations of plumbers are based on a choice model of hypothesized priorities as per the supplementary materials.
Providing a 20% subsidy directly to households when they choose whether to purchase an energy efficient product, regardless how or where they purchase it.
4.6These options have been explored individually as well as in combination as per Figure 7 and Table 11. It is clear that in this case, the monetary incentive through the Energy Savings Scheme is less efficient than the approach of influencing the recommendations of plumbers, and also less efficient than the 20% subsidy. Whether working with plumbers is more cost effective than providing a subsidy is unknown due to the difficulty in estimating the cost of influencing plumber recommendations.


Figure 7. Exploring the result of a set of possible interventions. X-axis: years. Y-axis: Adoption rates of solar hot water systems, as a proportion of all hot water systems. The plot has been generated in R based in simulation results (30 simulation runs for each policy setting), showing the standard errors as bars.
.
Table 11: Summary of scenario results. Notes. a: the unit is tonnes of CO2-e over a 30 year time period. b Calculated as the reduction per household above the baseline scenario.
CO2-e reduction per householda	Cost per hh per year (C)	Adoption rate 2047 (%)	Additional reduction (?)b
Baseline, i.e. no intervention	3.81	$0	68.6	-
ESS - $20	4.39	$19	75.5	0.58
ESS - $30	4.54	$29	76.5	0.73
Working with plumbers	5.93	Unknown	81.5	2.12
20 % subsidy	6.32	$17	88.9	2.51
Reflections
5.1The scenario analysis demonstrates that running model simulations provide insights beyond what is accessible with human cognitive functions. The model is able to explore where in the supply chain it is most cost-effective to incentivise decision making in order to promote the adoption of energy-efficient products.

5.2Furthermore, as is the strength of many ABMs when embedding socio-psychological models, the NED model is able to explore less tangible issues like common human biases in decision making, for example, the status quo bias, and the benefits of making adoption less of a hassle.

5.3In terms of specific results, the scenario analysis has shown that in the case of solar hot water systems and with of the described population, it is more cost effective to provide a subsidy to households rather than to incentivise sales agents via energy savings certificates. This is despite the fact that sales agents generate decision points that otherwise would not occur. This is somewhat counter-intuitive because otherwise subsidies only get activated when a product reaches the end of its life. Thus without marketing activities from sales agents, the maximum rate of the upgrade is dependent on the ageing of products and is limited.

5.4To validate this finding, regarding the effectiveness of providing a subsidy to households vs. incentivising sales agents, it will be necessary to collect better data on the model parameter, the ‘discount-effect’, which relates to the behavioural biases of mental accounting (Thaler 1985).

5.5Nonetheless, it seems likely it is more cost-effective to promote plumbers to recommend solar hot water systems. This shows the importance of providing the right information at the right time to households. In the case of solar hot water systems, plumbers engage with householders and have the opportunity to provide them with the right information at the right time.

5.6At a higher level, the model explorations also show that when modelling adoption processes, it is critical to understand the process of adoption, which can vary significantly depending on the type of intervention into the system. Embedding insights from behavioural science as much as possible allows for fine-tuning some key parameters in the delivery of interventions.

5.7Regarding the viability of the modelling approach, we believe it has potential to support plans to increase resource efficiency in society and thus can help improve sustainability outcomes. The approach is adaptable to many types of situations but will require some effort to tweak and update the models.

5.8To adapt the model to new contexts and interventions, the main task is in collecting the appropriate data, including surveys of households and key actors. Other actors that need to be surveyed are sales agents, information agents and supply chain actors. To illustrate the extent of data collection required, in a subsequent project where an adaptation of model is being developed on the topic of water conservation, the team has developed a standardised survey (requiring a couple of days to a week to adjust to new context next time), and in that context we surveyed 500 households which should suffice in most situations. The data collection for other agents, such as plumbers, supply chain actors or retailers, may be based on knowledge elicitation in a one-day workshop setting for each category.

5.9For those unfamiliar with ABM, the coding of the model is relatively straightforward, yet requires familiarity with the model itself, as well as some training in Agent-Based Modelling.

5.10The modelling capability described in this paper has here been applied to residential energy efficiency but adjustments of the model are being built to allow the analysis of interventions to increase household water conservation as well as shifting suburban commuter travel modes to low carbon alternatives.

Conclusions
6.1This paper provides the description of an ABM that represents the adoption processes of energy-efficient products. The computational engine has two sides of it, i.e. the Consumat meta-model of human behaviour which is based on social psychology theory, as well as the mapping of the processes of adoption. By applying the model to the case of solar hot water systems, a number of insights were generated, including the need to influence households at the right time and place, i.e. when the existing hot water system breaks down. The best approach for doing so is by influencing plumbers to recommend the installation of solar hot water systems. This can be achieved by providing them with training or educational materials. A particularly important insight is that it is not only residents that need to be incentivised; there can be an ecosystem of types of agents, and it is necessary to identify the most effective intervention point in the system. In the case of solar hot water systems, this intervention point appears to be the plumbers. In the future, this model will also be applied to the context of water conservation and low carbon transport.

Appendix
TPseudo-code to describe the NED model. The total code is several thousand lines, but here is an extract of some key methods.



Go method, i.e. providing the main time step
to go 
  while [year < endYear] [
    update-technologies
    update-discount
    set-price-of-energy-efficient-products
    evaluate-emissions-savings
    if InfluenceRecommendations = "a-strategy" 
[update-sales-agent-cost-parameters]
    update-decision-parameters
    ask-householders-to-make-upgrade-decisions
    ask-sales-agents-to-sell-energy-efficient-products
    updated-uptake-levels
    set year year + timesteplength
    updateCO2eSavings
    tick]
end

Householders making a decision:
to make-decision
  if mode = "imitate" [imitate]
  if mode = "repeat" [upgrade-with-same]
  if mode = "inquire" [inquire]
  if mode = "optimize" [optimize]
end

Householders setting their mode of decision making
to set-householder-mode
  check-social-satisfaction
  check-existential-satisfaction
  ask householders [set-mode]
end

Setup method, i.e. creating the model:
to setup 
  clear-all
  read-survey-data
  set-model-parameters
  setup-technology-options
  setup-gis-and-maps
  setup-social-network ;; this includes creating householder agents
  setup-householders
  setup-information-sources
  setup-sales-agents
  Reset-ticks
end